{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dlib in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (19.24.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp311-cp311-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.67.1-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading numpy-2.0.2-cp311-cp311-win_amd64.whl.metadata (59 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading h5py-3.12.1-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading optree-0.13.0-cp311-cp311-win_amd64.whl.metadata (48 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.18.0-cp311-cp311-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp311-cp311-win_amd64.whl (390.2 MB)\n",
      "   ---------------------------------------- 0.0/390.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/390.2 MB 9.3 MB/s eta 0:00:42\n",
      "   ---------------------------------------- 3.4/390.2 MB 8.0 MB/s eta 0:00:49\n",
      "    --------------------------------------- 5.2/390.2 MB 8.4 MB/s eta 0:00:46\n",
      "    --------------------------------------- 6.8/390.2 MB 8.2 MB/s eta 0:00:47\n",
      "    --------------------------------------- 8.1/390.2 MB 8.0 MB/s eta 0:00:48\n",
      "    --------------------------------------- 9.7/390.2 MB 7.7 MB/s eta 0:00:50\n",
      "   - -------------------------------------- 11.5/390.2 MB 7.9 MB/s eta 0:00:48\n",
      "   - -------------------------------------- 13.4/390.2 MB 8.0 MB/s eta 0:00:48\n",
      "   - -------------------------------------- 15.2/390.2 MB 8.0 MB/s eta 0:00:48\n",
      "   - -------------------------------------- 16.8/390.2 MB 8.0 MB/s eta 0:00:47\n",
      "   - -------------------------------------- 18.9/390.2 MB 8.1 MB/s eta 0:00:46\n",
      "   -- ------------------------------------- 20.4/390.2 MB 8.1 MB/s eta 0:00:46\n",
      "   -- ------------------------------------- 22.5/390.2 MB 8.2 MB/s eta 0:00:45\n",
      "   -- ------------------------------------- 24.6/390.2 MB 8.4 MB/s eta 0:00:44\n",
      "   -- ------------------------------------- 27.3/390.2 MB 8.6 MB/s eta 0:00:43\n",
      "   -- ------------------------------------- 29.1/390.2 MB 8.7 MB/s eta 0:00:42\n",
      "   --- ------------------------------------ 30.9/390.2 MB 8.6 MB/s eta 0:00:42\n",
      "   --- ------------------------------------ 33.3/390.2 MB 8.8 MB/s eta 0:00:41\n",
      "   --- ------------------------------------ 35.9/390.2 MB 9.0 MB/s eta 0:00:40\n",
      "   --- ------------------------------------ 38.5/390.2 MB 9.1 MB/s eta 0:00:39\n",
      "   ---- ----------------------------------- 40.9/390.2 MB 9.3 MB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 43.3/390.2 MB 9.3 MB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 45.1/390.2 MB 9.3 MB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 47.4/390.2 MB 9.3 MB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 49.3/390.2 MB 9.4 MB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 51.6/390.2 MB 9.4 MB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 53.5/390.2 MB 9.4 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 55.3/390.2 MB 9.3 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 57.1/390.2 MB 9.3 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 59.2/390.2 MB 9.3 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 61.3/390.2 MB 9.4 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 63.7/390.2 MB 9.4 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 66.3/390.2 MB 9.5 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 68.9/390.2 MB 9.6 MB/s eta 0:00:34\n",
      "   ------- -------------------------------- 71.3/390.2 MB 9.7 MB/s eta 0:00:34\n",
      "   ------- -------------------------------- 73.7/390.2 MB 9.7 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 76.0/390.2 MB 9.8 MB/s eta 0:00:33\n",
      "   -------- ------------------------------- 78.4/390.2 MB 9.8 MB/s eta 0:00:32\n",
      "   -------- ------------------------------- 80.0/390.2 MB 9.7 MB/s eta 0:00:32\n",
      "   -------- ------------------------------- 81.8/390.2 MB 9.7 MB/s eta 0:00:32\n",
      "   -------- ------------------------------- 83.9/390.2 MB 9.7 MB/s eta 0:00:32\n",
      "   -------- ------------------------------- 85.7/390.2 MB 9.6 MB/s eta 0:00:32\n",
      "   -------- ------------------------------- 87.6/390.2 MB 9.6 MB/s eta 0:00:32\n",
      "   --------- ------------------------------ 89.1/390.2 MB 9.6 MB/s eta 0:00:32\n",
      "   --------- ------------------------------ 90.7/390.2 MB 9.6 MB/s eta 0:00:32\n",
      "   --------- ------------------------------ 92.5/390.2 MB 9.5 MB/s eta 0:00:32\n",
      "   --------- ------------------------------ 94.6/390.2 MB 9.5 MB/s eta 0:00:32\n",
      "   --------- ------------------------------ 96.7/390.2 MB 9.5 MB/s eta 0:00:31\n",
      "   ---------- ----------------------------- 98.6/390.2 MB 9.5 MB/s eta 0:00:31\n",
      "   ---------- ----------------------------- 100.7/390.2 MB 9.5 MB/s eta 0:00:31\n",
      "   ---------- ----------------------------- 102.8/390.2 MB 9.5 MB/s eta 0:00:31\n",
      "   ---------- ----------------------------- 104.9/390.2 MB 9.5 MB/s eta 0:00:31\n",
      "   ---------- ----------------------------- 107.2/390.2 MB 9.5 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 109.6/390.2 MB 9.6 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 112.2/390.2 MB 9.6 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 114.3/390.2 MB 9.6 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 116.9/390.2 MB 9.7 MB/s eta 0:00:29\n",
      "   ------------ --------------------------- 119.0/390.2 MB 9.7 MB/s eta 0:00:29\n",
      "   ------------ --------------------------- 120.8/390.2 MB 9.6 MB/s eta 0:00:28\n",
      "   ------------ --------------------------- 122.4/390.2 MB 9.6 MB/s eta 0:00:28\n",
      "   ------------ --------------------------- 124.5/390.2 MB 9.6 MB/s eta 0:00:28\n",
      "   ------------ --------------------------- 126.6/390.2 MB 9.6 MB/s eta 0:00:28\n",
      "   ------------- -------------------------- 128.7/390.2 MB 9.6 MB/s eta 0:00:28\n",
      "   ------------- -------------------------- 131.1/390.2 MB 9.6 MB/s eta 0:00:27\n",
      "   ------------- -------------------------- 133.2/390.2 MB 9.6 MB/s eta 0:00:27\n",
      "   ------------- -------------------------- 135.3/390.2 MB 9.6 MB/s eta 0:00:27\n",
      "   -------------- ------------------------- 137.1/390.2 MB 9.6 MB/s eta 0:00:27\n",
      "   -------------- ------------------------- 139.2/390.2 MB 9.6 MB/s eta 0:00:27\n",
      "   -------------- ------------------------- 141.6/390.2 MB 9.6 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 143.7/390.2 MB 9.6 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 145.8/390.2 MB 9.6 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 147.6/390.2 MB 9.7 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 149.7/390.2 MB 9.7 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 151.8/390.2 MB 9.7 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 153.9/390.2 MB 9.7 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 156.0/390.2 MB 9.7 MB/s eta 0:00:25\n",
      "   ---------------- ----------------------- 158.1/390.2 MB 9.7 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 160.2/390.2 MB 9.7 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 162.3/390.2 MB 9.7 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 164.1/390.2 MB 9.7 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 165.4/390.2 MB 9.6 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 167.2/390.2 MB 9.6 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 169.1/390.2 MB 9.6 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 171.4/390.2 MB 9.6 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 173.5/390.2 MB 9.6 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 175.6/390.2 MB 9.6 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 177.7/390.2 MB 9.6 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 179.8/390.2 MB 9.6 MB/s eta 0:00:22\n",
      "   ------------------ --------------------- 181.9/390.2 MB 9.6 MB/s eta 0:00:22\n",
      "   ------------------ --------------------- 184.3/390.2 MB 9.7 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 186.1/390.2 MB 9.6 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 188.2/390.2 MB 9.7 MB/s eta 0:00:21\n",
      "   ------------------- -------------------- 190.3/390.2 MB 9.7 MB/s eta 0:00:21\n",
      "   ------------------- -------------------- 192.4/390.2 MB 9.7 MB/s eta 0:00:21\n",
      "   ------------------- -------------------- 194.5/390.2 MB 9.7 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 196.9/390.2 MB 9.7 MB/s eta 0:00:20\n",
      "   -------------------- ------------------- 199.0/390.2 MB 9.7 MB/s eta 0:00:20\n",
      "   -------------------- ------------------- 200.8/390.2 MB 9.7 MB/s eta 0:00:20\n",
      "   -------------------- ------------------- 202.9/390.2 MB 9.7 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 205.3/390.2 MB 9.7 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 206.6/390.2 MB 9.7 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 207.6/390.2 MB 9.6 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 209.7/390.2 MB 9.6 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 211.8/390.2 MB 9.6 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 214.2/390.2 MB 9.6 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 216.3/390.2 MB 9.6 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 218.6/390.2 MB 9.7 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 221.0/390.2 MB 9.7 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 223.3/390.2 MB 9.7 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 225.4/390.2 MB 9.7 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 227.3/390.2 MB 9.7 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 229.4/390.2 MB 9.7 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 231.7/390.2 MB 9.7 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 233.6/390.2 MB 9.7 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 236.2/390.2 MB 9.7 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 238.6/390.2 MB 9.7 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 240.9/390.2 MB 9.7 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 243.3/390.2 MB 9.7 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 245.4/390.2 MB 9.7 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 247.5/390.2 MB 9.7 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 250.3/390.2 MB 9.8 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 252.4/390.2 MB 9.8 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 255.3/390.2 MB 9.8 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 257.9/390.2 MB 9.8 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 259.8/390.2 MB 9.8 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 262.4/390.2 MB 9.8 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 264.5/390.2 MB 9.8 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 266.9/390.2 MB 9.9 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 268.7/390.2 MB 9.9 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 270.8/390.2 MB 9.9 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 272.6/390.2 MB 9.9 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 274.2/390.2 MB 9.9 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 276.3/390.2 MB 9.9 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 277.9/390.2 MB 9.9 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 278.9/390.2 MB 9.9 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 280.5/390.2 MB 9.9 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 282.9/390.2 MB 9.9 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 283.6/390.2 MB 9.9 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 285.5/390.2 MB 9.9 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 287.0/390.2 MB 9.8 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 289.1/390.2 MB 9.8 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 291.0/390.2 MB 9.8 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 292.8/390.2 MB 9.8 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 294.1/390.2 MB 9.8 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 296.2/390.2 MB 9.8 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 297.8/390.2 MB 9.7 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 300.2/390.2 MB 9.7 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 302.0/390.2 MB 9.7 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 303.8/390.2 MB 9.7 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 305.7/390.2 MB 9.7 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 308.0/390.2 MB 9.7 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 309.9/390.2 MB 9.7 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 312.0/390.2 MB 9.7 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 314.3/390.2 MB 9.7 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 316.7/390.2 MB 9.7 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 318.8/390.2 MB 9.8 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 321.4/390.2 MB 9.8 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 323.5/390.2 MB 9.8 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 325.6/390.2 MB 9.8 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 327.7/390.2 MB 9.7 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 330.0/390.2 MB 9.8 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 331.9/390.2 MB 9.7 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 334.5/390.2 MB 9.7 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 336.6/390.2 MB 9.7 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 339.2/390.2 MB 9.7 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 341.0/390.2 MB 9.7 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 343.1/390.2 MB 9.8 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 345.0/390.2 MB 9.8 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 347.3/390.2 MB 9.8 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 348.7/390.2 MB 9.8 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 350.7/390.2 MB 9.8 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 352.6/390.2 MB 9.8 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 354.2/390.2 MB 9.8 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 356.0/390.2 MB 9.8 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 357.8/390.2 MB 9.8 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 359.4/390.2 MB 9.8 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 361.2/390.2 MB 9.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 362.8/390.2 MB 9.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 364.6/390.2 MB 9.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 367.0/390.2 MB 9.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 369.1/390.2 MB 9.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 370.9/390.2 MB 9.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 372.8/390.2 MB 9.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 374.9/390.2 MB 9.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 377.2/390.2 MB 9.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 379.3/390.2 MB 9.7 MB/s eta 0:00:02\n",
      "   ---------------------------------------  381.2/390.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  383.3/390.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  385.4/390.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  387.7/390.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  389.0/390.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  390.1/390.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 390.2/390.2 MB 9.2 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.67.1-cp311-cp311-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 2.1/4.4 MB 10.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.2/4.4 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.4/4.4 MB 9.7 MB/s eta 0:00:00\n",
      "Downloading h5py-3.12.1-cp311-cp311-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 2.1/3.0 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 9.8 MB/s eta 0:00:00\n",
      "Downloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 8.4 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.4/26.4 MB 12.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 4.7/26.4 MB 11.9 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 7.3/26.4 MB 11.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 9.7/26.4 MB 11.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.3/26.4 MB 11.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.7/26.4 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 17.0/26.4 MB 11.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 19.4/26.4 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 22.0/26.4 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.4/26.4 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 11.2 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl (126 kB)\n",
      "Downloading numpy-2.0.2-cp311-cp311-win_amd64.whl (15.9 MB)\n",
      "   ---------------------------------------- 0.0/15.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 2.4/15.9 MB 12.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 5.0/15.9 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 7.3/15.9 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.7/15.9 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 12.1/15.9 MB 11.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.2/15.9 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.9 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.9/15.9 MB 10.8 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 1.8/5.5 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 9.6 MB/s eta 0:00:00\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 9.8 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl (37 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl (101 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading werkzeug-3.1.1-py3-none-any.whl (224 kB)\n",
      "Using cached wheel-0.44.0-py3-none-any.whl (67 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.0-cp311-cp311-win_amd64.whl (283 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, urllib3, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, MarkupSafe, markdown, idna, grpcio, google-pasta, gast, charset-normalizer, certifi, absl-py, werkzeug, requests, ml-dtypes, markdown-it-py, h5py, astunparse, tensorboard, rich, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.1.0 astunparse-1.6.3 certifi-2024.8.30 charset-normalizer-3.4.0 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.67.1 h5py-3.12.1 idna-3.10 keras-3.6.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.13.0 protobuf-5.28.3 requests-2.32.3 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.5.0 urllib3-2.2.3 werkzeug-3.1.1 wheel-0.44.0 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.14.1\n",
      "  Downloading tensorflow-2.14.1-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.14.1 (from tensorflow==2.14.1)\n",
      "  Downloading tensorflow_intel-2.14.1-cp311-cp311-win_amd64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.1->tensorflow==2.14.1) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.1->tensorflow==2.14.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.1->tensorflow==2.14.1) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.1->tensorflow==2.14.1) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.1->tensorflow==2.14.1) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.1->tensorflow==2.14.1) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.1->tensorflow==2.14.1) (18.1.1)\n",
      "Collecting ml-dtypes==0.2.0 (from tensorflow-intel==2.14.1->tensorflow==2.14.1)\n",
      "  Downloading ml_dtypes-0.2.0-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow-intel==2.14.1->tensorflow==2.14.1)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.1->tensorflow==2.14.1) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.14.1->tensorflow==2.14.1) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.14.1->tensorflow==2.14.1)\n",
      "  Downloading protobuf-4.25.5-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.1->tensorflow==2.14.1) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.14.1->tensorflow==2.14.1) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.1->tensorflow==2.14.1) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.14.1->tensorflow==2.14.1) (4.12.2)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow-intel==2.14.1->tensorflow==2.14.1)\n",
      "  Downloading wrapt-1.14.1-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.1->tensorflow==2.14.1) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.1->tensorflow==2.14.1) (1.67.1)\n",
      "Collecting tensorboard<2.15,>=2.14 (from tensorflow-intel==2.14.1->tensorflow==2.14.1)\n",
      "  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow-intel==2.14.1->tensorflow==2.14.1)\n",
      "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.15,>=2.14.0 (from tensorflow-intel==2.14.1->tensorflow==2.14.1)\n",
      "  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.1->tensorflow==2.14.1) (0.44.0)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.1->tensorflow==2.14.1)\n",
      "  Downloading google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.1->tensorflow==2.14.1)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.1->tensorflow==2.14.1) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.1->tensorflow==2.14.1) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.1->tensorflow==2.14.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.1->tensorflow==2.14.1) (3.1.1)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.1->tensorflow==2.14.1)\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.1->tensorflow==2.14.1)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.1->tensorflow==2.14.1)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.1->tensorflow==2.14.1)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.1->tensorflow==2.14.1) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.1->tensorflow==2.14.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.1->tensorflow==2.14.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.1->tensorflow==2.14.1) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.1->tensorflow==2.14.1) (3.0.2)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.1->tensorflow==2.14.1)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.1->tensorflow==2.14.1)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Downloading tensorflow-2.14.1-cp311-cp311-win_amd64.whl (2.1 kB)\n",
      "Downloading tensorflow_intel-2.14.1-cp311-cp311-win_amd64.whl (284.2 MB)\n",
      "   ---------------------------------------- 0.0/284.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/284.2 MB 11.8 MB/s eta 0:00:24\n",
      "    --------------------------------------- 4.5/284.2 MB 11.2 MB/s eta 0:00:26\n",
      "    --------------------------------------- 6.8/284.2 MB 11.7 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 8.1/284.2 MB 11.2 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 10.5/284.2 MB 10.9 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 13.4/284.2 MB 10.9 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 15.7/284.2 MB 11.0 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 18.4/284.2 MB 11.1 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 20.7/284.2 MB 11.2 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 23.1/284.2 MB 11.2 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 25.4/284.2 MB 11.3 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 27.3/284.2 MB 11.3 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 28.6/284.2 MB 10.7 MB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 31.2/284.2 MB 10.8 MB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 33.6/284.2 MB 10.8 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 35.9/284.2 MB 10.9 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 38.5/284.2 MB 10.9 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 40.9/284.2 MB 11.0 MB/s eta 0:00:23\n",
      "   ------ --------------------------------- 43.3/284.2 MB 11.0 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 45.6/284.2 MB 11.0 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 46.7/284.2 MB 10.7 MB/s eta 0:00:23\n",
      "   ------ --------------------------------- 49.0/284.2 MB 10.8 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 51.4/284.2 MB 10.8 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 54.0/284.2 MB 10.8 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 56.4/284.2 MB 10.9 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 58.2/284.2 MB 10.8 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 60.6/284.2 MB 10.8 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 62.9/284.2 MB 10.9 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 65.0/284.2 MB 10.9 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 65.0/284.2 MB 10.9 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 65.0/284.2 MB 10.9 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 66.8/284.2 MB 10.1 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 69.2/284.2 MB 10.1 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 71.3/284.2 MB 10.1 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 72.6/284.2 MB 10.0 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 74.7/284.2 MB 10.0 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 77.1/284.2 MB 10.0 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 79.4/284.2 MB 10.1 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 81.8/284.2 MB 10.1 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 84.1/284.2 MB 10.1 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 84.4/284.2 MB 10.0 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 86.8/284.2 MB 9.9 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 89.4/284.2 MB 10.0 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 91.5/284.2 MB 10.0 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 93.8/284.2 MB 10.0 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 96.2/284.2 MB 10.1 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 98.8/284.2 MB 10.1 MB/s eta 0:00:19\n",
      "   ------------- ------------------------- 101.4/284.2 MB 10.1 MB/s eta 0:00:19\n",
      "   -------------- ------------------------ 103.8/284.2 MB 10.2 MB/s eta 0:00:18\n",
      "   -------------- ------------------------ 105.6/284.2 MB 10.2 MB/s eta 0:00:18\n",
      "   -------------- ------------------------ 108.3/284.2 MB 10.2 MB/s eta 0:00:18\n",
      "   --------------- ----------------------- 110.6/284.2 MB 10.2 MB/s eta 0:00:17\n",
      "   --------------- ----------------------- 113.0/284.2 MB 10.2 MB/s eta 0:00:17\n",
      "   --------------- ----------------------- 114.8/284.2 MB 10.2 MB/s eta 0:00:17\n",
      "   ---------------- ---------------------- 116.9/284.2 MB 10.2 MB/s eta 0:00:17\n",
      "   ---------------- ---------------------- 118.8/284.2 MB 10.2 MB/s eta 0:00:17\n",
      "   ---------------- ---------------------- 120.8/284.2 MB 10.2 MB/s eta 0:00:17\n",
      "   ---------------- ---------------------- 122.7/284.2 MB 10.1 MB/s eta 0:00:16\n",
      "   ----------------- --------------------- 124.5/284.2 MB 10.1 MB/s eta 0:00:16\n",
      "   ----------------- --------------------- 126.4/284.2 MB 10.1 MB/s eta 0:00:16\n",
      "   ----------------- --------------------- 128.2/284.2 MB 10.1 MB/s eta 0:00:16\n",
      "   ----------------- --------------------- 130.3/284.2 MB 10.1 MB/s eta 0:00:16\n",
      "   ------------------ -------------------- 132.1/284.2 MB 10.1 MB/s eta 0:00:16\n",
      "   ------------------ -------------------- 134.2/284.2 MB 10.1 MB/s eta 0:00:15\n",
      "   ------------------ -------------------- 136.3/284.2 MB 10.0 MB/s eta 0:00:15\n",
      "   ------------------ -------------------- 138.1/284.2 MB 10.0 MB/s eta 0:00:15\n",
      "   ------------------ -------------------- 138.4/284.2 MB 10.0 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 139.2/284.2 MB 9.8 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 141.3/284.2 MB 9.8 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 143.4/284.2 MB 9.8 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 145.2/284.2 MB 9.8 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 147.3/284.2 MB 9.8 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 149.4/284.2 MB 9.8 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 151.8/284.2 MB 9.8 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 154.1/284.2 MB 9.8 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 156.5/284.2 MB 9.8 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 158.9/284.2 MB 9.9 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 161.5/284.2 MB 9.9 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 163.8/284.2 MB 9.9 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 166.2/284.2 MB 9.9 MB/s eta 0:00:12\n",
      "   ----------------------- --------------- 168.6/284.2 MB 10.0 MB/s eta 0:00:12\n",
      "   ----------------------- --------------- 171.2/284.2 MB 10.0 MB/s eta 0:00:12\n",
      "   ----------------------- --------------- 173.0/284.2 MB 10.0 MB/s eta 0:00:12\n",
      "   ----------------------- --------------- 173.0/284.2 MB 10.0 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 175.1/284.2 MB 9.9 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 177.5/284.2 MB 9.9 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 180.1/284.2 MB 9.9 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 182.5/284.2 MB 9.9 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 184.3/284.2 MB 9.9 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 184.8/284.2 MB 9.8 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 187.2/284.2 MB 9.8 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 189.5/284.2 MB 9.9 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 191.9/284.2 MB 9.9 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 194.0/284.2 MB 9.9 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 195.0/284.2 MB 9.9 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 196.6/284.2 MB 9.8 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 199.2/284.2 MB 9.8 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 201.6/284.2 MB 9.8 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 203.9/284.2 MB 9.8 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 206.3/284.2 MB 9.9 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 207.9/284.2 MB 9.8 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 209.7/284.2 MB 9.8 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 212.1/284.2 MB 9.8 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 214.7/284.2 MB 9.9 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 217.1/284.2 MB 9.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 219.7/284.2 MB 9.9 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 222.0/284.2 MB 9.9 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 223.9/284.2 MB 9.9 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 226.5/284.2 MB 9.9 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 228.3/284.2 MB 9.9 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 230.2/284.2 MB 9.9 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 232.3/284.2 MB 9.9 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 234.9/284.2 MB 9.9 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 237.2/284.2 MB 10.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 239.6/284.2 MB 10.0 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 241.7/284.2 MB 10.0 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 244.8/284.2 MB 10.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 246.4/284.2 MB 10.0 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 249.0/284.2 MB 10.0 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 251.4/284.2 MB 10.0 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 253.5/284.2 MB 10.0 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 255.9/284.2 MB 10.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 257.9/284.2 MB 10.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 259.5/284.2 MB 10.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 261.9/284.2 MB 10.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 264.0/284.2 MB 10.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 265.3/284.2 MB 10.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 267.1/284.2 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 269.0/284.2 MB 9.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 271.1/284.2 MB 9.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 272.9/284.2 MB 9.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 274.7/284.2 MB 9.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 276.6/284.2 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  278.1/284.2 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  280.5/284.2 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  282.1/284.2 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  284.2/284.2 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  284.2/284.2 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 284.2/284.2 MB 9.7 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.2.0-cp311-cp311-win_amd64.whl (938 kB)\n",
      "   ---------------------------------------- 0.0/938.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 938.7/938.7 kB 8.7 MB/s eta 0:00:00\n",
      "Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 11.6 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 2.4/15.8 MB 12.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.5/15.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 7.1/15.8 MB 11.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.2/15.8 MB 11.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.8/15.8 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.7/15.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 11.1 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.25.5-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.3/5.5 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 11.2 MB/s eta 0:00:00\n",
      "Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
      "Downloading wrapt-1.14.1-cp311-cp311-win_amd64.whl (35 kB)\n",
      "Downloading google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
      "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: wrapt, tensorflow-estimator, pyasn1, protobuf, oauthlib, numpy, keras, cachetools, rsa, requests-oauthlib, pyasn1-modules, ml-dtypes, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.16.0\n",
      "    Uninstalling wrapt-1.16.0:\n",
      "      Successfully uninstalled wrapt-1.16.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.28.3\n",
      "    Uninstalling protobuf-5.28.3:\n",
      "      Successfully uninstalled protobuf-5.28.3\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.6.0\n",
      "    Uninstalling keras-3.6.0:\n",
      "      Successfully uninstalled keras-3.6.0\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.4.1\n",
      "    Uninstalling ml-dtypes-0.4.1:\n",
      "      Successfully uninstalled ml-dtypes-0.4.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.18.0\n",
      "    Uninstalling tensorboard-2.18.0:\n",
      "      Successfully uninstalled tensorboard-2.18.0\n",
      "  Attempting uninstall: tensorflow-intel\n",
      "    Found existing installation: tensorflow_intel 2.18.0\n",
      "    Uninstalling tensorflow_intel-2.18.0:\n",
      "      Successfully uninstalled tensorflow_intel-2.18.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.18.0\n",
      "    Uninstalling tensorflow-2.18.0:\n",
      "      Successfully uninstalled tensorflow-2.18.0\n",
      "Successfully installed cachetools-5.5.0 google-auth-2.35.0 google-auth-oauthlib-1.0.0 keras-2.14.0 ml-dtypes-0.2.0 numpy-1.26.4 oauthlib-3.2.2 protobuf-4.25.5 pyasn1-0.6.1 pyasn1-modules-0.4.1 requests-oauthlib-2.0.0 rsa-4.9 tensorboard-2.14.1 tensorflow-2.14.1 tensorflow-estimator-2.14.0 tensorflow-intel-2.14.1 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.14.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.17.0\n",
      "  Downloading tensorflow-2.17.0-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow==2.17.0)\n",
      "  Downloading tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (18.1.1)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel==2.17.0->tensorflow==2.17.0)\n",
      "  Using cached ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (1.67.1)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.0->tensorflow==2.17.0)\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow-intel==2.17.0->tensorflow==2.17.0)\n",
      "  Using cached keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow==2.17.0) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow==2.17.0) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow==2.17.0) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.1.2)\n",
      "Downloading tensorflow-2.17.0-cp311-cp311-win_amd64.whl (2.0 kB)\n",
      "Downloading tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl (385.0 MB)\n",
      "   ---------------------------------------- 0.0/385.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/385.0 MB 11.2 MB/s eta 0:00:35\n",
      "   ---------------------------------------- 4.5/385.0 MB 11.7 MB/s eta 0:00:33\n",
      "    --------------------------------------- 6.6/385.0 MB 11.2 MB/s eta 0:00:34\n",
      "    --------------------------------------- 8.9/385.0 MB 11.1 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 10.5/385.0 MB 11.3 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 11.5/385.0 MB 9.5 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 13.6/385.0 MB 9.5 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 15.7/385.0 MB 9.5 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 17.8/385.0 MB 9.7 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 20.7/385.0 MB 9.9 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 23.1/385.0 MB 10.1 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 25.4/385.0 MB 10.2 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 28.0/385.0 MB 10.4 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 30.7/385.0 MB 10.5 MB/s eta 0:00:34\n",
      "   --- ------------------------------------ 33.0/385.0 MB 10.6 MB/s eta 0:00:34\n",
      "   --- ------------------------------------ 35.4/385.0 MB 10.7 MB/s eta 0:00:33\n",
      "   --- ------------------------------------ 38.0/385.0 MB 10.7 MB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 40.4/385.0 MB 10.7 MB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 43.0/385.0 MB 10.9 MB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 45.4/385.0 MB 10.8 MB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 47.2/385.0 MB 10.8 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 49.3/385.0 MB 10.7 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 51.6/385.0 MB 10.7 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 54.0/385.0 MB 10.8 MB/s eta 0:00:31\n",
      "   ----- ---------------------------------- 56.6/385.0 MB 10.8 MB/s eta 0:00:31\n",
      "   ------ --------------------------------- 59.0/385.0 MB 10.9 MB/s eta 0:00:31\n",
      "   ------ --------------------------------- 61.6/385.0 MB 10.9 MB/s eta 0:00:30\n",
      "   ------ --------------------------------- 64.0/385.0 MB 10.9 MB/s eta 0:00:30\n",
      "   ------ --------------------------------- 66.6/385.0 MB 11.0 MB/s eta 0:00:30\n",
      "   ------- -------------------------------- 68.9/385.0 MB 11.0 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 71.3/385.0 MB 11.0 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 73.7/385.0 MB 11.0 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 76.0/385.0 MB 11.1 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 78.6/385.0 MB 11.1 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 81.0/385.0 MB 11.1 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 83.4/385.0 MB 11.1 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 85.5/385.0 MB 11.1 MB/s eta 0:00:27\n",
      "   --------- ------------------------------ 87.6/385.0 MB 11.1 MB/s eta 0:00:27\n",
      "   --------- ------------------------------ 89.4/385.0 MB 11.0 MB/s eta 0:00:27\n",
      "   --------- ------------------------------ 90.7/385.0 MB 10.9 MB/s eta 0:00:28\n",
      "   --------- ------------------------------ 92.3/385.0 MB 10.8 MB/s eta 0:00:28\n",
      "   --------- ------------------------------ 93.8/385.0 MB 10.7 MB/s eta 0:00:28\n",
      "   --------- ------------------------------ 95.4/385.0 MB 10.7 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 97.3/385.0 MB 10.6 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 99.1/385.0 MB 10.6 MB/s eta 0:00:28\n",
      "   ---------- ---------------------------- 100.9/385.0 MB 10.5 MB/s eta 0:00:27\n",
      "   ---------- ---------------------------- 102.8/385.0 MB 10.5 MB/s eta 0:00:27\n",
      "   ---------- ---------------------------- 104.6/385.0 MB 10.5 MB/s eta 0:00:27\n",
      "   ---------- ---------------------------- 106.7/385.0 MB 10.5 MB/s eta 0:00:27\n",
      "   ----------- --------------------------- 108.8/385.0 MB 10.5 MB/s eta 0:00:27\n",
      "   ----------- --------------------------- 111.1/385.0 MB 10.5 MB/s eta 0:00:27\n",
      "   ----------- --------------------------- 113.2/385.0 MB 10.5 MB/s eta 0:00:26\n",
      "   ----------- --------------------------- 115.6/385.0 MB 10.5 MB/s eta 0:00:26\n",
      "   ----------- --------------------------- 118.2/385.0 MB 10.5 MB/s eta 0:00:26\n",
      "   ------------ -------------------------- 120.6/385.0 MB 10.5 MB/s eta 0:00:26\n",
      "   ------------ -------------------------- 121.9/385.0 MB 10.5 MB/s eta 0:00:26\n",
      "   ------------ -------------------------- 122.9/385.0 MB 10.4 MB/s eta 0:00:26\n",
      "   ------------ -------------------------- 123.7/385.0 MB 10.3 MB/s eta 0:00:26\n",
      "   ------------ -------------------------- 125.0/385.0 MB 10.2 MB/s eta 0:00:26\n",
      "   ------------ -------------------------- 126.1/385.0 MB 10.1 MB/s eta 0:00:26\n",
      "   ------------ -------------------------- 127.4/385.0 MB 10.0 MB/s eta 0:00:26\n",
      "   ------------- ------------------------- 128.7/385.0 MB 10.0 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 130.0/385.0 MB 9.9 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 131.6/385.0 MB 9.9 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 132.9/385.0 MB 9.8 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 134.5/385.0 MB 9.8 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 136.3/385.0 MB 9.8 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 137.9/385.0 MB 9.7 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 139.7/385.0 MB 9.7 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 141.6/385.0 MB 9.7 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 143.7/385.0 MB 9.7 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 145.5/385.0 MB 9.7 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 147.6/385.0 MB 9.7 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 149.7/385.0 MB 9.7 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 151.8/385.0 MB 9.7 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 153.9/385.0 MB 9.7 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 156.2/385.0 MB 9.7 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 158.3/385.0 MB 9.8 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 160.7/385.0 MB 9.8 MB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 163.1/385.0 MB 9.8 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 165.4/385.0 MB 9.8 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 167.5/385.0 MB 9.8 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 169.6/385.0 MB 9.8 MB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 171.7/385.0 MB 9.8 MB/s eta 0:00:22\n",
      "   ------------------ --------------------- 173.8/385.0 MB 9.8 MB/s eta 0:00:22\n",
      "   ------------------ --------------------- 176.2/385.0 MB 9.8 MB/s eta 0:00:22\n",
      "   ------------------ --------------------- 178.5/385.0 MB 9.9 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 180.9/385.0 MB 9.9 MB/s eta 0:00:21\n",
      "   ------------------- -------------------- 183.2/385.0 MB 9.9 MB/s eta 0:00:21\n",
      "   ------------------- -------------------- 185.6/385.0 MB 9.9 MB/s eta 0:00:21\n",
      "   ------------------- ------------------- 188.2/385.0 MB 10.0 MB/s eta 0:00:20\n",
      "   ------------------- ------------------- 190.6/385.0 MB 10.0 MB/s eta 0:00:20\n",
      "   ------------------- ------------------- 192.9/385.0 MB 10.0 MB/s eta 0:00:20\n",
      "   ------------------- ------------------- 195.6/385.0 MB 10.0 MB/s eta 0:00:19\n",
      "   -------------------- ------------------ 197.9/385.0 MB 10.0 MB/s eta 0:00:19\n",
      "   -------------------- ------------------ 199.5/385.0 MB 10.0 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 200.3/385.0 MB 9.9 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 201.3/385.0 MB 9.9 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 202.1/385.0 MB 9.8 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 203.2/385.0 MB 9.8 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 203.7/385.0 MB 9.7 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 205.0/385.0 MB 9.7 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 206.0/385.0 MB 9.6 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 207.4/385.0 MB 9.6 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 208.9/385.0 MB 9.6 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 210.2/385.0 MB 9.6 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 211.8/385.0 MB 9.5 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 213.4/385.0 MB 9.5 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 215.0/385.0 MB 9.5 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 216.5/385.0 MB 9.5 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 218.4/385.0 MB 9.5 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 220.2/385.0 MB 9.5 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 222.0/385.0 MB 9.5 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 224.1/385.0 MB 9.5 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 226.0/385.0 MB 9.5 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 228.1/385.0 MB 9.5 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 230.2/385.0 MB 9.5 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 232.5/385.0 MB 9.5 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 234.6/385.0 MB 9.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 237.0/385.0 MB 9.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 239.3/385.0 MB 9.5 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 241.7/385.0 MB 9.5 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 244.1/385.0 MB 9.6 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 246.4/385.0 MB 9.6 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 248.8/385.0 MB 9.6 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 250.6/385.0 MB 9.6 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 252.7/385.0 MB 9.6 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 254.5/385.0 MB 9.6 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 256.6/385.0 MB 9.6 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 259.0/385.0 MB 9.6 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 261.4/385.0 MB 9.6 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 263.7/385.0 MB 9.6 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 266.3/385.0 MB 9.6 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 268.7/385.0 MB 9.6 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 271.1/385.0 MB 9.6 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 273.4/385.0 MB 9.7 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 275.8/385.0 MB 9.7 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 278.4/385.0 MB 9.7 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 280.8/385.0 MB 9.7 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 283.1/385.0 MB 9.7 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 285.5/385.0 MB 9.7 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 288.1/385.0 MB 9.7 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 290.2/385.0 MB 9.7 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 292.0/385.0 MB 9.7 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 293.1/385.0 MB 9.7 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 294.1/385.0 MB 9.6 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 295.2/385.0 MB 9.6 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 295.7/385.0 MB 9.6 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 295.7/385.0 MB 9.6 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 296.0/385.0 MB 9.4 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 297.3/385.0 MB 9.3 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 298.3/385.0 MB 9.3 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 299.6/385.0 MB 9.3 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 300.9/385.0 MB 9.2 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 302.5/385.0 MB 9.2 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 303.8/385.0 MB 9.2 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 305.1/385.0 MB 9.2 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 306.4/385.0 MB 9.1 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 308.0/385.0 MB 9.1 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 309.9/385.0 MB 9.1 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 311.7/385.0 MB 9.1 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 313.3/385.0 MB 9.1 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 314.8/385.0 MB 9.1 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 316.9/385.0 MB 9.0 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 318.8/385.0 MB 9.0 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 320.3/385.0 MB 9.0 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 321.9/385.0 MB 9.0 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 323.7/385.0 MB 9.0 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 325.8/385.0 MB 9.0 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 327.9/385.0 MB 9.0 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 329.3/385.0 MB 8.9 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 331.6/385.0 MB 8.9 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 333.7/385.0 MB 8.9 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 336.1/385.0 MB 8.9 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 337.9/385.0 MB 8.9 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 340.0/385.0 MB 8.9 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 342.1/385.0 MB 8.9 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 344.5/385.0 MB 8.9 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 346.6/385.0 MB 8.9 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 348.7/385.0 MB 8.8 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 350.5/385.0 MB 8.8 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 352.8/385.0 MB 8.9 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 355.2/385.0 MB 8.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 357.8/385.0 MB 8.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 360.2/385.0 MB 9.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 362.5/385.0 MB 9.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 363.9/385.0 MB 9.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 365.7/385.0 MB 9.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 368.1/385.0 MB 9.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 369.9/385.0 MB 8.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 371.5/385.0 MB 8.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 372.8/385.0 MB 8.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 374.3/385.0 MB 8.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  375.9/385.0 MB 8.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  377.5/385.0 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  379.3/385.0 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  380.9/385.0 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  382.5/385.0 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.3/385.0 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.8/385.0 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.8/385.0 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.8/385.0 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.8/385.0 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  384.8/385.0 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 385.0/385.0 MB 8.6 MB/s eta 0:00:00\n",
      "Using cached keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl (126 kB)\n",
      "Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.7/5.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 10.8 MB/s eta 0:00:00\n",
      "Installing collected packages: ml-dtypes, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.2.0\n",
      "    Uninstalling ml-dtypes-0.2.0:\n",
      "      Successfully uninstalled ml-dtypes-0.2.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.14.1\n",
      "    Uninstalling tensorboard-2.14.1:\n",
      "      Successfully uninstalled tensorboard-2.14.1\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.14.0\n",
      "    Uninstalling keras-2.14.0:\n",
      "      Successfully uninstalled keras-2.14.0\n",
      "  Attempting uninstall: tensorflow-intel\n",
      "    Found existing installation: tensorflow-intel 2.14.1\n",
      "    Uninstalling tensorflow-intel-2.14.1:\n",
      "      Successfully uninstalled tensorflow-intel-2.14.1\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.14.1\n",
      "    Uninstalling tensorflow-2.14.1:\n",
      "      Successfully uninstalled tensorflow-2.14.1\n",
      "Successfully installed keras-3.6.0 ml-dtypes-0.4.1 tensorboard-2.17.1 tensorflow-2.17.0 tensorflow-intel-2.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.17.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face_recognition==1.2.3\n",
      "  Downloading face_recognition-1.2.3-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting Click>=6.0 (from face_recognition==1.2.3)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting Pillow (from face_recognition==1.2.3)\n",
      "  Downloading pillow-11.0.0-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: dlib>=19.7 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face_recognition==1.2.3) (19.24.1)\n",
      "Collecting face-recognition-models>=0.3.0 (from face_recognition==1.2.3)\n",
      "  Using cached face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face_recognition==1.2.3) (1.26.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from Click>=6.0->face_recognition==1.2.3) (0.4.6)\n",
      "Downloading face_recognition-1.2.3-py2.py3-none-any.whl (21 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading pillow-11.0.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 1.8/2.6 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 11.4 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: face-recognition-models\n",
      "  Building wheel for face-recognition-models (setup.py): started\n",
      "  Building wheel for face-recognition-models (setup.py): finished with status 'done'\n",
      "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566183 sha256=a881e432cccb302ef631659f155b9fe851919c7f381c08de4c55c67e6371e4d9\n",
      "  Stored in directory: c:\\users\\b vishnu\\appdata\\local\\pip\\cache\\wheels\\04\\52\\ec\\9355da79c29f160b038a20c784db2803c2f9fa2c8a462c176a\n",
      "Successfully built face-recognition-models\n",
      "Installing collected packages: face-recognition-models, Pillow, Click, face_recognition\n",
      "Successfully installed Click-8.1.7 Pillow-11.0.0 face-recognition-models-0.3.0 face_recognition-1.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install face_recognition==1.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement retinaface==0.0.17 (from versions: 0.0.1, 0.0.2, 0.0.3, 0.0.4, 0.0.5, 0.0.6, 1.1.0, 1.1.1)\n",
      "ERROR: No matching distribution found for retinaface==0.0.17\n"
     ]
    }
   ],
   "source": [
    "!pip install retinaface==0.0.17 tensorflow==2.17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting retinaface\n",
      "  Using cached retinaface-1.1.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "INFO: pip is looking at multiple versions of retinaface to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached retinaface-1.1.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "  Using cached retinaface-0.0.6-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached retinaface-0.0.5-py3-none-any.whl.metadata (1.4 kB)\n",
      "  Using cached retinaface-0.0.4-py3-none-any.whl.metadata (725 bytes)\n",
      "  Using cached retinaface-0.0.3-py3-none-any.whl.metadata (725 bytes)\n",
      "  Using cached retinaface-0.0.2-py3-none-any.whl.metadata (725 bytes)\n",
      "  Using cached retinaface-0.0.1-py3-none-any.whl.metadata (725 bytes)\n",
      "INFO: pip is still looking at multiple versions of retinaface to determine which version is compatible with other requirements. This could take a while.\n",
      "\n",
      "The conflict is caused by:\n",
      "    retinaface 1.1.1 depends on tensorflow==2.5.0\n",
      "    retinaface 1.1.0 depends on tensorflow==2.5.0\n",
      "    retinaface 0.0.6 depends on tensorflow==2.1.0\n",
      "    retinaface 0.0.5 depends on tensorflow==2.1.0\n",
      "    retinaface 0.0.4 depends on tensorflow==2.1.0\n",
      "    retinaface 0.0.3 depends on tensorflow==2.1.0\n",
      "    retinaface 0.0.2 depends on tensorflow==2.1.0\n",
      "    retinaface 0.0.1 depends on tensorflow==2.1.0\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install retinaface==0.0.1, retinaface==0.0.2, retinaface==0.0.3, retinaface==0.0.4, retinaface==0.0.5, retinaface==0.0.6, retinaface==1.1.0 and retinaface==1.1.1 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    }
   ],
   "source": [
    "!pip install retinaface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (24.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting retina-face==0.0.17\n",
      "  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from retina-face==0.0.17) (1.26.4)\n",
      "Collecting gdown>=3.10.1 (from retina-face==0.0.17)\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from retina-face==0.0.17) (11.0.0)\n",
      "Collecting opencv-python>=3.4.4 (from retina-face==0.0.17)\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: tensorflow>=1.9.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from retina-face==0.0.17) (2.17.0)\n",
      "Collecting beautifulsoup4 (from gdown>=3.10.1->retina-face==0.0.17)\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting filelock (from gdown>=3.10.1->retina-face==0.0.17)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gdown>=3.10.1->retina-face==0.0.17) (2.32.3)\n",
      "Collecting tqdm (from gdown>=3.10.1->retina-face==0.0.17)\n",
      "  Downloading tqdm-4.66.6-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow>=1.9.0->retina-face==0.0.17) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (4.25.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (0.31.0)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->gdown>=3.10.1->retina-face==0.0.17)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->retina-face==0.0.17) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->retina-face==0.0.17) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->retina-face==0.0.17) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->retina-face==0.0.17) (2024.8.30)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown>=3.10.1->retina-face==0.0.17)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->gdown>=3.10.1->retina-face==0.0.17) (0.4.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (0.13.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow>=1.9.0->retina-face==0.0.17) (0.1.2)\n",
      "Downloading retina_face-0.0.17-py3-none-any.whl (25 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading tqdm-4.66.6-py3-none-any.whl (78 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: tqdm, soupsieve, PySocks, opencv-python, filelock, beautifulsoup4, gdown, retina-face\n",
      "Successfully installed PySocks-1.7.1 beautifulsoup4-4.12.3 filelock-3.16.1 gdown-5.2.0 opencv-python-4.10.0.84 retina-face-0.0.17 soupsieve-2.6 tqdm-4.66.6\n"
     ]
    }
   ],
   "source": [
    "!pip install retina-face==0.0.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/11.6 MB 5.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.4/11.6 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.8/11.6 MB 9.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.1/11.6 MB 9.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.5/11.6 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 10.0 MB/s eta 0:00:00\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2024.2 tzdata-2024.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tensorflow<2.19,>=2.18 (from tf-keras)\n",
      "  Using cached tensorflow-2.18.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Using cached tensorflow_intel-2.18.0-cp311-cp311-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.67.1)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\b vishnu\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\b vishnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 1.3/1.7 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 8.5 MB/s eta 0:00:00\n",
      "Using cached tensorflow-2.18.0-cp311-cp311-win_amd64.whl (7.5 kB)\n",
      "Using cached tensorflow_intel-2.18.0-cp311-cp311-win_amd64.whl (390.2 MB)\n",
      "Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Installing collected packages: tensorboard, tensorflow-intel, tensorflow, tf-keras\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.17.1\n",
      "    Uninstalling tensorboard-2.17.1:\n",
      "      Successfully uninstalled tensorboard-2.17.1\n",
      "  Attempting uninstall: tensorflow-intel\n",
      "    Found existing installation: tensorflow-intel 2.17.0\n",
      "    Uninstalling tensorflow-intel-2.17.0:\n",
      "      Successfully uninstalled tensorflow-intel-2.17.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.17.0\n",
      "    Uninstalling tensorflow-2.17.0:\n",
      "      Successfully uninstalled tensorflow-2.17.0\n",
      "Successfully installed tensorboard-2.18.0 tensorflow-2.18.0 tensorflow-intel-2.18.0 tf-keras-2.18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\~ensorflow'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Downloading pymongo-4.10.1-cp311-cp311-win_amd64.whl.metadata (22 kB)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Downloading pymongo-4.10.1-cp311-cp311-win_amd64.whl (876 kB)\n",
      "   ---------------------------------------- 0.0/876.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 876.5/876.5 kB 7.9 MB/s eta 0:00:00\n",
      "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Installing collected packages: dnspython, pymongo\n",
      "Successfully installed dnspython-2.7.0 pymongo-4.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Loaded known faces.\n",
      "Entry detected for v at 2024-11-03 12:46:38\n",
      "Exit detected for v at 2024-11-03 12:49:12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 179\u001b[0m\n\u001b[0;32m    176\u001b[0m start_date \u001b[38;5;241m=\u001b[39m datetime(\u001b[38;5;241m2024\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdate()  \u001b[38;5;66;03m# Set your desired start date\u001b[39;00m\n\u001b[0;32m    177\u001b[0m initialize_attendance_data(known_names, start_date)\n\u001b[1;32m--> 179\u001b[0m \u001b[43mrecognize_faces_multi_camera\u001b[49m\u001b[43m(\u001b[49m\u001b[43mknown_faces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 131\u001b[0m, in \u001b[0;36mrecognize_faces_multi_camera\u001b[1;34m(known_faces, known_names)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Process entry camera\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m \u001b[43mprocess_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mentry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_faces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_entry_times\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# Process exit camera\u001b[39;00m\n\u001b[0;32m    134\u001b[0m process_frame(frame_exit, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m, known_faces, known_names, last_entry_times)\n",
      "Cell \u001b[1;32mIn[1], line 150\u001b[0m, in \u001b[0;36mprocess_frame\u001b[1;34m(frame, event_type, known_faces, known_names, last_entry_times)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_frame\u001b[39m(frame, event_type, known_faces, known_names, last_entry_times):\n\u001b[0;32m    149\u001b[0m     frame_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m--> 150\u001b[0m     faces \u001b[38;5;241m=\u001b[39m \u001b[43mRetinaFace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_faces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m     face_names \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m face_key \u001b[38;5;129;01min\u001b[39;00m faces\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\retinaface\\RetinaFace.py:123\u001b[0m, in \u001b[0;36mdetect_faces\u001b[1;34m(img_path, threshold, model, allow_upscaling)\u001b[0m\n\u001b[0;32m    121\u001b[0m landmarks_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    122\u001b[0m im_tensor, im_info, im_scale \u001b[38;5;241m=\u001b[39m preprocess\u001b[38;5;241m.\u001b[39mpreprocess_image(img, allow_upscaling)\n\u001b[1;32m--> 123\u001b[0m net_out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m net_out \u001b[38;5;241m=\u001b[39m [elt\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m elt \u001b[38;5;129;01min\u001b[39;00m net_out]\n\u001b[0;32m    125\u001b[0m sym_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from retinaface import RetinaFace\n",
    "import face_recognition\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pymongo\n",
    "\n",
    "# MongoDB setup\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"attendance_db\"]\n",
    "students_collection = db[\"students\"]\n",
    "\n",
    "# Constants\n",
    "TOLERANCE = 0.6\n",
    "MINIMUM_DURATION = 1  # Minimum duration in minutes to log attendance\n",
    "TOTAL_PERIODS = 6  # Total number of periods in a day\n",
    "\n",
    "# Load known faces and their encodings\n",
    "def load_known_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    KNOWN_FACES_DIR = r\"D:\\minor\\Training_images\"  # Update with your path\n",
    "    for name in os.listdir(KNOWN_FACES_DIR):\n",
    "        for filename in os.listdir(f\"{KNOWN_FACES_DIR}/{name}\"):\n",
    "            image = face_recognition.load_image_file(f\"{KNOWN_FACES_DIR}/{name}/{filename}\")\n",
    "            encodings = face_recognition.face_encodings(image)\n",
    "            if encodings:\n",
    "                known_faces.append(encodings[0])\n",
    "                known_names.append(name)\n",
    "    print(\"Loaded known faces.\")\n",
    "    return known_faces, known_names\n",
    "\n",
    "# Initialize attendance data in MongoDB with a start date\n",
    "def initialize_attendance_data(known_names, start_date):\n",
    "    start_date_str = start_date.isoformat()  # Convert date to string format 'YYYY-MM-DD'\n",
    "    today_str = datetime.now().date().isoformat()  # Today's date\n",
    "\n",
    "    # Reset today's attendance data\n",
    "    students_collection.delete_many({\"date\": today_str})  \n",
    "\n",
    "    for name in known_names:\n",
    "        attendance_record = {\n",
    "            'name': name,\n",
    "            'date': today_str,\n",
    "            'start_date': start_date_str,\n",
    "            'attendance': {f'Period {i+1}': 0 for i in range(TOTAL_PERIODS)},\n",
    "            'total_attended': 0,\n",
    "            'total_days': 0,\n",
    "            'percentage': 100\n",
    "        }\n",
    "        students_collection.insert_one(attendance_record)\n",
    "\n",
    "# Determine current period based on the current time\n",
    "def get_period_index(current_time):\n",
    "    PERIOD_TIMES = [\n",
    "        (9, 10),   # Period 1: 9-10 am\n",
    "        (10, 11),  # Period 2: 10-11 am\n",
    "        (11, 12),  # Period 3: 11-12 pm\n",
    "        (13, 14),  # Period 4: 1-2 pm\n",
    "        (14, 15),  # Period 5: 2-3 pm\n",
    "        (15, 16)   # Period 6: 3-4 pm\n",
    "    ]\n",
    "    for i, (start, end) in enumerate(PERIOD_TIMES):\n",
    "        if start <= current_time.hour < end:\n",
    "            return i  # Return the period index (0 for Period 1, etc.)\n",
    "    return None  # Return None if outside period times\n",
    "\n",
    "# Update attendance for each period based on entry and exit times\n",
    "def update_attendance(name, timestamp, event_type, last_entry_times):\n",
    "    current_time = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')\n",
    "    period_index = get_period_index(current_time)\n",
    "\n",
    "    today_str = current_time.date().isoformat()  # Convert to string format\n",
    "\n",
    "    if period_index is not None:\n",
    "        period_key = f'Period {period_index + 1}'\n",
    "\n",
    "        if event_type == 'entry':\n",
    "            last_entry_times[name] = current_time  # Store entry time\n",
    "        elif event_type == 'exit' and name in last_entry_times:\n",
    "            entry_time = last_entry_times.pop(name)  # Retrieve and remove the entry time\n",
    "            duration = (current_time - entry_time).total_seconds() / 60  # Convert to minutes\n",
    "\n",
    "            # Log attendance only if the duration is at least MINIMUM_DURATION\n",
    "            if duration >= MINIMUM_DURATION:\n",
    "                # Increment attendance for the current period\n",
    "                students_collection.update_one(\n",
    "                    {'name': name, 'date': today_str},\n",
    "                    {'$inc': {f'attendance.{period_key}': 1, 'total_attended': 1}}\n",
    "                )\n",
    "\n",
    "                # Retrieve the current attendance record\n",
    "                attendance_record = students_collection.find_one({'name': name, 'date': today_str})\n",
    "                total_attended = attendance_record['total_attended']\n",
    "\n",
    "                # Calculate total days using the stored start date\n",
    "                start_date = datetime.strptime(attendance_record['start_date'], '%Y-%m-%d').date()\n",
    "                total_days = (datetime.now().date() - start_date).days\n",
    "\n",
    "                # Ensure total_days is not zero\n",
    "                if total_days <= 0:\n",
    "                    total_days = 1\n",
    "\n",
    "                # Update the attendance percentage\n",
    "                attendance_percentage = (total_attended / (total_days * TOTAL_PERIODS)) * 100\n",
    "\n",
    "                # Update the attendance percentage in MongoDB\n",
    "                students_collection.update_one(\n",
    "                    {'name': name, 'date': today_str},\n",
    "                    {'$set': {'percentage': attendance_percentage, 'total_days': total_days}}\n",
    "                )\n",
    "                print(f\"Updated attendance for {name} for {period_key} (duration: {duration:.2f} mins)\")\n",
    "\n",
    "# Recognize faces from entry and exit cameras and process attendance\n",
    "def recognize_faces_multi_camera(known_faces, known_names):\n",
    "    cap_entry = cv2.VideoCapture(0)  # Entry camera\n",
    "    cap_exit = cv2.VideoCapture(1)   # Exit camera\n",
    "\n",
    "    last_entry_times = {}  # Dictionary to track last entry times for each person\n",
    "\n",
    "    while True:\n",
    "        # Read frames from both entry and exit cameras\n",
    "        ret_entry, frame_entry = cap_entry.read()\n",
    "        ret_exit, frame_exit = cap_exit.read()\n",
    "        if not ret_entry or not ret_exit:\n",
    "            break\n",
    "\n",
    "        # Process entry camera\n",
    "        process_frame(frame_entry, 'entry', known_faces, known_names, last_entry_times)\n",
    "\n",
    "        # Process exit camera\n",
    "        process_frame(frame_exit, 'exit', known_faces, known_names, last_entry_times)\n",
    "\n",
    "        # Display frames for entry and exit cameras\n",
    "        cv2.imshow('Entry Camera', frame_entry)\n",
    "        cv2.imshow('Exit Camera', frame_exit)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap_entry.release()\n",
    "    cap_exit.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Process frames for entry or exit events\n",
    "def process_frame(frame, event_type, known_faces, known_names, last_entry_times):\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    faces = RetinaFace.detect_faces(frame)\n",
    "    face_names = []\n",
    "    for face_key in faces.keys():\n",
    "        facial_area = faces[face_key][\"facial_area\"]\n",
    "        top, right, bottom, left = facial_area[1], facial_area[2], facial_area[3], facial_area[0]\n",
    "        encodings = face_recognition.face_encodings(frame_rgb, [(top, right, bottom, left)])\n",
    "\n",
    "        for encoding in encodings:\n",
    "            matches = face_recognition.compare_faces(known_faces, encoding, TOLERANCE)\n",
    "            name = \"Unknown\"\n",
    "            face_distances = face_recognition.face_distance(known_faces, encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_names[best_match_index]\n",
    "            face_names.append(name)\n",
    "\n",
    "    # Log detected names and timestamps\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    for name in face_names:\n",
    "        if name != \"Unknown\":\n",
    "            update_attendance(name, timestamp, event_type, last_entry_times)\n",
    "            print(f\"{event_type.capitalize()} detected for {name} at {timestamp}\")\n",
    "\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    known_faces, known_names = load_known_faces()\n",
    "    start_date = datetime(2024, 1, 1).date()  # Set your desired start date\n",
    "    initialize_attendance_data(known_names, start_date)\n",
    "\n",
    "    recognize_faces_multi_camera(known_faces, known_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded known faces.\n",
      "Entry detected for v at 2024-11-03 11:29:39\n",
      "Entry detected for v at 2024-11-03 11:29:47\n",
      "Entry detected for v at 2024-11-03 11:30:06\n",
      "Updated attendance for v for Period 3 (duration: 2.20 mins)\n",
      "Exit detected for v at 2024-11-03 11:32:18\n",
      "Exit detected for v at 2024-11-03 11:32:26\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 168\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    167\u001b[0m     known_faces, known_names \u001b[38;5;241m=\u001b[39m load_known_faces()\n\u001b[1;32m--> 168\u001b[0m     \u001b[43mrecognize_faces_multi_camera\u001b[49m\u001b[43m(\u001b[49m\u001b[43mknown_faces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 123\u001b[0m, in \u001b[0;36mrecognize_faces_multi_camera\u001b[1;34m(known_faces, known_names)\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Process entry camera\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43mprocess_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mentry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_faces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_entry_times\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# Process exit camera\u001b[39;00m\n\u001b[0;32m    126\u001b[0m process_frame(frame_exit, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m, known_faces, known_names, last_entry_times)\n",
      "Cell \u001b[1;32mIn[4], line 142\u001b[0m, in \u001b[0;36mprocess_frame\u001b[1;34m(frame, event_type, known_faces, known_names, last_entry_times)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_frame\u001b[39m(frame, event_type, known_faces, known_names, last_entry_times):\n\u001b[0;32m    141\u001b[0m     frame_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m--> 142\u001b[0m     faces \u001b[38;5;241m=\u001b[39m \u001b[43mRetinaFace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_faces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     face_names \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m face_key \u001b[38;5;129;01min\u001b[39;00m faces\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\retinaface\\RetinaFace.py:123\u001b[0m, in \u001b[0;36mdetect_faces\u001b[1;34m(img_path, threshold, model, allow_upscaling)\u001b[0m\n\u001b[0;32m    121\u001b[0m landmarks_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    122\u001b[0m im_tensor, im_info, im_scale \u001b[38;5;241m=\u001b[39m preprocess\u001b[38;5;241m.\u001b[39mpreprocess_image(img, allow_upscaling)\n\u001b[1;32m--> 123\u001b[0m net_out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m net_out \u001b[38;5;241m=\u001b[39m [elt\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m elt \u001b[38;5;129;01min\u001b[39;00m net_out]\n\u001b[0;32m    125\u001b[0m sym_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#code2 connect mongo\n",
    "import cv2\n",
    "import numpy as np\n",
    "from retinaface import RetinaFace\n",
    "import face_recognition\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Directory containing known faces\n",
    "KNOWN_FACES_DIR = r\"D:\\minor\\Training_images\"\n",
    "TOLERANCE = 0.6\n",
    "\n",
    "# Constants for periods and attendance calculation\n",
    "PERIOD_TIMES = [\n",
    "    (9, 10),   # Period 1: 9-10 am\n",
    "    (10, 11),  # Period 2: 10-11 am\n",
    "    (11, 12),  # Period 3: 11-12 pm\n",
    "    (13, 14),  # Period 4: 1-2 pm\n",
    "    (14, 15),  # Period 5: 2-3 pm\n",
    "    (0, 1)   # Period 6: 3-4 pm\n",
    "]\n",
    "TOTAL_PERIODS = len(PERIOD_TIMES)\n",
    "MINIMUM_DURATION = 1  # Minimum duration in minutes to log attendance\n",
    "\n",
    "# MongoDB setup\n",
    "MONGO_URI = \"mongodb://localhost:27017/\"  # Replace with your MongoDB URI\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[\"attendance_db\"]  # Create/use a database called attendance_db\n",
    "students_collection = db[\"students\"]  # Create/use a collection called students\n",
    "\n",
    "# Load known faces and their encodings\n",
    "def load_known_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    for name in os.listdir(KNOWN_FACES_DIR):\n",
    "        for filename in os.listdir(f\"{KNOWN_FACES_DIR}/{name}\"):\n",
    "            image = face_recognition.load_image_file(f\"{KNOWN_FACES_DIR}/{name}/{filename}\")\n",
    "            encodings = face_recognition.face_encodings(image)\n",
    "            if encodings:\n",
    "                known_faces.append(encodings[0])\n",
    "                known_names.append(name)\n",
    "    print(\"Loaded known faces.\")\n",
    "    return known_faces, known_names\n",
    "\n",
    "# Initialize attendance data in MongoDB\n",
    "def initialize_attendance_data(known_names):\n",
    "    today = datetime.now().date()\n",
    "    today_str = today.isoformat()  # Convert date to string format 'YYYY-MM-DD'\n",
    "    students_collection.delete_many({\"date\": today_str})  # Reset today's attendance data\n",
    "\n",
    "    for name in known_names:\n",
    "        attendance_record = {\n",
    "            'name': name,\n",
    "            'date': today_str,  # Store date as string\n",
    "            'attendance': {f'Period {i+1}': 0 for i in range(TOTAL_PERIODS)},\n",
    "            'total': 0,\n",
    "            'percentage': 100\n",
    "        }\n",
    "        students_collection.insert_one(attendance_record)\n",
    "\n",
    "# Determine current period based on the current time\n",
    "def get_period_index(current_time):\n",
    "    for i, (start, end) in enumerate(PERIOD_TIMES):\n",
    "        if start <= current_time.hour < end:\n",
    "            return i  # Return the period index (0 for Period 1, etc.)\n",
    "    return None  # Return None if outside period times\n",
    "\n",
    "# Update attendance for each period based on entry and exit times\n",
    "# def update_attendance(name, timestamp, event_type, last_entry_times):\n",
    "#     current_time = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')\n",
    "#     period_index = get_period_index(current_time)\n",
    "\n",
    "#     today_str = current_time.date().isoformat()  # Convert to string format\n",
    "\n",
    "#     if period_index is not None:\n",
    "#         period_key = f'Period {period_index + 1}'\n",
    "\n",
    "#         if event_type == 'entry':\n",
    "#             last_entry_times[name] = current_time  # Store entry time\n",
    "#         elif event_type == 'exit' and name in last_entry_times:\n",
    "#             entry_time = last_entry_times.pop(name)  # Retrieve and remove the entry time\n",
    "#             duration = (current_time - entry_time).total_seconds() / 60  # Convert to minutes\n",
    "\n",
    "#             # Log attendance only if the duration is at least MINIMUM_DURATION\n",
    "#             if duration >= MINIMUM_DURATION:\n",
    "#                 # Increment attendance for the current period\n",
    "#                 students_collection.update_one(\n",
    "#                     {'name': name, 'date': today_str},\n",
    "#                     {'$inc': {f'attendance.{period_key}': 1, 'total': 1}}\n",
    "#                 )\n",
    "\n",
    "#                 # Calculate new total attendance and percentage\n",
    "#                 attendance_record = students_collection.find_one({'name': name, 'date': today_str})\n",
    "#                 total_attended = attendance_record['total']\n",
    "#                 total_possible_periods = TOTAL_PERIODS  # Adjust based on your requirements\n",
    "#                 attendance_percentage = (total_attended / total_possible_periods) * 100\n",
    "\n",
    "#                 # Update the attendance percentage\n",
    "#                 students_collection.update_one(\n",
    "#                     {'name': name, 'date': today_str},\n",
    "#                     {'$set': {'percentage': attendance_percentage}}\n",
    "#                 )\n",
    "#                 print(f\"Updated attendance for {name} for {period_key} (duration: {duration:.2f} mins)\")\n",
    "\n",
    "# Update attendance for each period based on entry and exit times\n",
    "def update_attendance(name, timestamp, event_type, last_entry_times):\n",
    "    current_time = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')\n",
    "    period_index = get_period_index(current_time)\n",
    "\n",
    "    today_str = current_time.date().isoformat()  # Convert to string format\n",
    "\n",
    "    if period_index is not None:\n",
    "        period_key = f'Period {period_index + 1}'\n",
    "\n",
    "        if event_type == 'entry':\n",
    "            last_entry_times[name] = current_time  # Store entry time\n",
    "        elif event_type == 'exit' and name in last_entry_times:\n",
    "            entry_time = last_entry_times.pop(name)  # Retrieve and remove the entry time\n",
    "            duration = (current_time - entry_time).total_seconds() / 60  # Convert to minutes\n",
    "\n",
    "            # Log attendance only if the duration is at least MINIMUM_DURATION\n",
    "            if duration >= MINIMUM_DURATION:\n",
    "                # Increment attendance for the current period\n",
    "                students_collection.update_one(\n",
    "                    {'name': name, 'date': today_str},\n",
    "                    {'$inc': {f'attendance.{period_key}': 1, 'total': 1}}\n",
    "                )\n",
    "\n",
    "                # Retrieve the current attendance record\n",
    "                attendance_record = students_collection.find_one({'name': name, 'date': today_str})\n",
    "                total_attended = attendance_record['total']\n",
    "                \n",
    "                # Calculate the total days of attendance records (not including today)\n",
    "                total_days = (datetime.now().date() - datetime.strptime(attendance_record['date'], '%Y-%m-%d').date()).days\n",
    "\n",
    "                # Check if today’s attendance was recorded (1 for present)\n",
    "                todays_attendance = 1  # Set this to 0 if the student was absent today\n",
    "\n",
    "                # Update the attendance percentage using the provided formula\n",
    "                updated_percentage = ((total_attended * total_days) + todays_attendance) / (total_days + 1) * 100\n",
    "\n",
    "                # Update the attendance percentage in MongoDB\n",
    "                students_collection.update_one(\n",
    "                    {'name': name, 'date': today_str},\n",
    "                    {'$set': {'percentage': updated_percentage}}\n",
    "                )\n",
    "                print(f\"Updated attendance for {name} for {period_key} (duration: {duration:.2f} mins)\")\n",
    "\n",
    "\n",
    "# Recognize faces from entry and exit cameras and process attendance\n",
    "def recognize_faces_multi_camera(known_faces, known_names):\n",
    "    cap_entry = cv2.VideoCapture(0)  # Entry camera\n",
    "    cap_exit = cv2.VideoCapture(1)   # Exit camera\n",
    "\n",
    "    initialize_attendance_data(known_names)\n",
    "    last_entry_times = {}  # Dictionary to track last entry times for each person\n",
    "\n",
    "    while True:\n",
    "        # Read frames from both entry and exit cameras\n",
    "        ret_entry, frame_entry = cap_entry.read()\n",
    "        ret_exit, frame_exit = cap_exit.read()\n",
    "        if not ret_entry or not ret_exit:\n",
    "            break\n",
    "\n",
    "        # Process entry camera\n",
    "        process_frame(frame_entry, 'entry', known_faces, known_names, last_entry_times)\n",
    "\n",
    "        # Process exit camera\n",
    "        process_frame(frame_exit, 'exit', known_faces, known_names, last_entry_times)\n",
    "\n",
    "        # Display frames for entry and exit cameras\n",
    "        cv2.imshow('Entry Camera', frame_entry)\n",
    "        cv2.imshow('Exit Camera', frame_exit)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap_entry.release()\n",
    "    cap_exit.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Process frames for entry or exit events\n",
    "def process_frame(frame, event_type, known_faces, known_names, last_entry_times):\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    faces = RetinaFace.detect_faces(frame)\n",
    "    face_names = []\n",
    "    for face_key in faces.keys():\n",
    "        facial_area = faces[face_key][\"facial_area\"]\n",
    "        top, right, bottom, left = facial_area[1], facial_area[2], facial_area[3], facial_area[0]\n",
    "        encodings = face_recognition.face_encodings(frame_rgb, [(top, right, bottom, left)])\n",
    "\n",
    "        for encoding in encodings:\n",
    "            matches = face_recognition.compare_faces(known_faces, encoding, TOLERANCE)\n",
    "            name = \"Unknown\"\n",
    "            face_distances = face_recognition.face_distance(known_faces, encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_names[best_match_index]\n",
    "            face_names.append(name)\n",
    "    \n",
    "    # Log detected names and timestamps\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    for name in face_names:\n",
    "        if name != \"Unknown\":\n",
    "            update_attendance(name, timestamp, event_type, last_entry_times)\n",
    "            print(f\"{event_type.capitalize()} detected for {name} at {timestamp}\")\n",
    "\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    known_faces, known_names = load_known_faces()\n",
    "    recognize_faces_multi_camera(known_faces, known_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Loaded known faces.\n",
      "Entry detected for v at 2024-11-03 00:22:51\n",
      "Exit detected for v at 2024-11-03 00:23:01\n",
      "Entry detected for v at 2024-11-03 00:23:31\n",
      "Updated attendance for v for Period 6 (duration: 2.37 mins)\n",
      "Exit detected for v at 2024-11-03 00:25:53\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from retinaface import RetinaFace\n",
    "import face_recognition\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Directory containing known faces\n",
    "KNOWN_FACES_DIR = r\"D:\\minor\\Training_images\"\n",
    "TOLERANCE = 0.6\n",
    "FRAME_THICKNESS = 3\n",
    "FONT_THICKNESS = 2\n",
    "MODEL = \"cnn\"\n",
    "\n",
    "# Constants for periods and attendance calculation\n",
    "PERIOD_TIMES = [\n",
    "    (9, 10),   # Period 1: 9-10 am\n",
    "    (10, 11),  # Period 2: 10-11 am\n",
    "    (11, 12),  # Period 3: 11-12 pm\n",
    "    (13, 14),  # Period 4: 1-2 pm\n",
    "    (14, 15),  # Period 5: 2-3 pm\n",
    "    (0, 1)   # Period 6: 3-4 pm\n",
    "]\n",
    "TOTAL_PERIODS = len(PERIOD_TIMES)\n",
    "MINIMUM_DURATION = 1  # Minimum duration in minutes to log attendance\n",
    "\n",
    "# Load known faces and their encodings\n",
    "def load_known_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    for name in os.listdir(KNOWN_FACES_DIR):\n",
    "        for filename in os.listdir(f\"{KNOWN_FACES_DIR}/{name}\"):\n",
    "            image = face_recognition.load_image_file(f\"{KNOWN_FACES_DIR}/{name}/{filename}\")\n",
    "            encodings = face_recognition.face_encodings(image)\n",
    "            if encodings:\n",
    "                known_faces.append(encodings[0])\n",
    "                known_names.append(name)\n",
    "    print(\"Loaded known faces.\")\n",
    "    return known_faces, known_names\n",
    "\n",
    "  # Initialize or update attendance file with columns for each period and Total and Percentage\n",
    "def initialize_attendance_file(known_names):\n",
    "    attendance_file = r'D:\\minor\\Attend.xlsx'\n",
    "    if not os.path.exists(attendance_file):\n",
    "        columns = ['Name', 'Date'] + [f'Period {i+1}' for i in range(TOTAL_PERIODS)] + ['Total', 'Percentage']\n",
    "        attendance_data = pd.DataFrame(columns=columns)\n",
    "        attendance_data['Name'] = pd.Series(known_names).unique() \n",
    "        attendance_data['Percentage'] = 100\n",
    "        attendance_data['Date'] = datetime.now().date()  # Set today's date\n",
    "        attendance_data.fillna(0, inplace=True)  # Set initial attendance to 0\n",
    "        attendance_data.to_excel(attendance_file, index=False)\n",
    "    else:\n",
    "        attendance_data = pd.read_excel(attendance_file, engine='openpyxl')\n",
    "    return attendance_data\n",
    "\n",
    "\n",
    "# Determine current period based on the current time\n",
    "def get_period_index(current_time):\n",
    "    for i, (start, end) in enumerate(PERIOD_TIMES):\n",
    "        if start <= current_time.hour < end:\n",
    "            return i  # Return the period index (0 for Period 1, etc.)\n",
    "    return None  # Return None if outside period times\n",
    "\n",
    "# Update attendance for each period based on entry and exit times\n",
    "# Update attendance for each period based on entry and exit times\n",
    "def update_attendance(name, timestamp, event_type, attendance_data, last_entry_times):\n",
    "    attendance_file = r'D:\\minor\\Attend.xlsx'\n",
    "    current_time = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')\n",
    "    period_index = get_period_index(current_time)\n",
    "\n",
    "    if period_index is not None:\n",
    "        period_col = f'Period {period_index + 1}'\n",
    "\n",
    "        if event_type == 'entry':\n",
    "            last_entry_times[name] = current_time  # Store entry time\n",
    "        elif event_type == 'exit' and name in last_entry_times:\n",
    "            entry_time = last_entry_times.pop(name)  # Retrieve and remove the entry time\n",
    "            duration = (current_time - entry_time).total_seconds() / 60  # Convert to minutes\n",
    "\n",
    "            # Log attendance only if the duration is at least MINIMUM_DURATION\n",
    "            if duration >= MINIMUM_DURATION:\n",
    "                # Increment attendance for the current period\n",
    "                attendance_data.loc[attendance_data['Name'] == name, period_col] += 1\n",
    "                \n",
    "                # Update total attendance\n",
    "                current_total = attendance_data.loc[attendance_data['Name'] == name, 'Total'].iloc[0]\n",
    "                new_total = current_total + 1  # Increase total attendance count by 1\n",
    "                attendance_data.loc[attendance_data['Name'] == name, 'Total'] = new_total\n",
    "                \n",
    "                # Update total periods attended\n",
    "                total_periods_attended = attendance_data.loc[attendance_data['Name'] == name, 'Total'].iloc[0]\n",
    "                \n",
    "                # Update the total possible periods (this would need to consider the total number of periods over time)\n",
    "                # For this example, let's assume TOTAL_PERIODS is constant. If it changes, you need to adjust accordingly.\n",
    "                total_possible_periods = TOTAL_PERIODS * (datetime.now().date() - attendance_data['Date'].min().date()).days\n",
    "                \n",
    "                # Calculate the attendance percentage\n",
    "                attendance_data.loc[attendance_data['Name'] == name, 'Percentage'] = (total_periods_attended / total_possible_periods) * 100\n",
    "                \n",
    "                # Save updated attendance data to Excel\n",
    "                attendance_data.to_excel(attendance_file, index=False)\n",
    "                print(f\"Updated attendance for {name} for {period_col} (duration: {duration:.2f} mins)\")\n",
    "\n",
    "\n",
    "\n",
    "# Recognize faces from entry and exit cameras and process attendance\n",
    "def recognize_faces_multi_camera(known_faces, known_names):\n",
    "    cap_entry = cv2.VideoCapture(0)  # Entry camera\n",
    "    cap_exit = cv2.VideoCapture(1)   # Exit camera\n",
    "\n",
    "    attendance_data = initialize_attendance_file(known_names)\n",
    "    last_entry_times = {}  # Dictionary to track last entry times for each person\n",
    "\n",
    "    while True:\n",
    "        # Read frames from both entry and exit cameras\n",
    "        ret_entry, frame_entry = cap_entry.read()\n",
    "        ret_exit, frame_exit = cap_exit.read()\n",
    "        if not ret_entry or not ret_exit:\n",
    "            break\n",
    "\n",
    "        # Process entry camera\n",
    "        process_frame(frame_entry, 'entry', known_faces, known_names, attendance_data, last_entry_times)\n",
    "\n",
    "        # Process exit camera\n",
    "        process_frame(frame_exit, 'exit', known_faces, known_names, attendance_data, last_entry_times)\n",
    "\n",
    "        # Display frames for entry and exit cameras\n",
    "        cv2.imshow('Entry Camera', frame_entry)\n",
    "        cv2.imshow('Exit Camera', frame_exit)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap_entry.release()\n",
    "    cap_exit.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Process frames for entry or exit events\n",
    "def process_frame(frame, event_type, known_faces, known_names, attendance_data, last_entry_times):\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    faces = RetinaFace.detect_faces(frame)\n",
    "    face_names = []\n",
    "    for face_key in faces.keys():\n",
    "        facial_area = faces[face_key][\"facial_area\"]\n",
    "        top, right, bottom, left = facial_area[1], facial_area[2], facial_area[3], facial_area[0]\n",
    "        encodings = face_recognition.face_encodings(frame_rgb, [(top, right, bottom, left)])\n",
    "\n",
    "        for encoding in encodings:\n",
    "            matches = face_recognition.compare_faces(known_faces, encoding, TOLERANCE)\n",
    "            name = \"Unknown\"\n",
    "            face_distances = face_recognition.face_distance(known_faces, encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_names[best_match_index]\n",
    "            face_names.append(name)\n",
    "    # Log detected names and timestamps\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    for name in face_names:\n",
    "        if name != \"Unknown\":\n",
    "            update_attendance(name, timestamp, event_type, attendance_data, last_entry_times)\n",
    "            print(f\"{event_type.capitalize()} detected for {name} at {timestamp}\")\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    known_faces, known_names = load_known_faces()\n",
    "    recognize_faces_multi_camera(known_faces, known_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#code new\n",
    "import cv2\n",
    "import numpy as np\n",
    "from retinaface import RetinaFace\n",
    "import face_recognition\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pymongo import MongoClient  # Add MongoDB library\n",
    "\n",
    "# MongoDB setup\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['attendance_db']  # Database name\n",
    "collection = db['students_attendance']  # Collection name\n",
    "\n",
    "KNOWN_FACES_DIR = r\"D:\\minor\\Training_images\"\n",
    "TOLERANCE = 0.6\n",
    "FRAME_THICKNESS = 3\n",
    "FONT_THICKNESS = 2\n",
    "MODEL = \"cnn\"\n",
    "\n",
    "# Constants for periods and attendance calculation\n",
    "PERIOD_TIMES = [\n",
    "    (9, 10), (10, 11), (11, 12), (13, 14), (14, 15), (15, 16)\n",
    "]\n",
    "TOTAL_PERIODS = len(PERIOD_TIMES)\n",
    "MINIMUM_DURATION = 1\n",
    "\n",
    "# Load known faces and their encodings\n",
    "def load_known_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "    for name in os.listdir(KNOWN_FACES_DIR):\n",
    "        for filename in os.listdir(f\"{KNOWN_FACES_DIR}/{name}\"):\n",
    "            image = face_recognition.load_image_file(f\"{KNOWN_FACES_DIR}/{name}/{filename}\")\n",
    "            encodings = face_recognition.face_encodings(image)\n",
    "            if encodings:\n",
    "                known_faces.append(encodings[0])\n",
    "                known_names.append(name)\n",
    "    return known_faces, known_names\n",
    "\n",
    "# Initialize or update attendance file\n",
    "def initialize_attendance_file(known_names):\n",
    "    attendance_file = r'D:\\minor\\Attend.xlsx'\n",
    "    if not os.path.exists(attendance_file):\n",
    "        columns = ['Name', 'Date'] + [f'Period {i+1}' for i in range(TOTAL_PERIODS)] + ['Total', 'Percentage']\n",
    "        attendance_data = pd.DataFrame(columns=columns)\n",
    "        attendance_data['Name'] = pd.Series(known_names).unique() \n",
    "        attendance_data['Percentage'] = 100\n",
    "        attendance_data['Date'] = datetime.now().date()\n",
    "        attendance_data.fillna(0, inplace=True)\n",
    "        attendance_data.to_excel(attendance_file, index=False)\n",
    "    else:\n",
    "        attendance_data = pd.read_excel(attendance_file, engine='openpyxl')\n",
    "    return attendance_data\n",
    "\n",
    "# Get period index\n",
    "def get_period_index(current_time):\n",
    "    for i, (start, end) in enumerate(PERIOD_TIMES):\n",
    "        if start <= current_time.hour < end:\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "# Update attendance for each period\n",
    "def update_attendance(name, timestamp, event_type, attendance_data, last_entry_times):\n",
    "    attendance_file = r'D:\\minor\\Attend.xlsx'\n",
    "    current_time = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')\n",
    "    period_index = get_period_index(current_time)\n",
    "    if period_index is not None:\n",
    "        period_col = f'Period {period_index + 1}'\n",
    "        if event_type == 'entry':\n",
    "            last_entry_times[name] = current_time\n",
    "        elif event_type == 'exit' and name in last_entry_times:\n",
    "            entry_time = last_entry_times.pop(name)\n",
    "            duration = (current_time - entry_time).total_seconds() / 60\n",
    "            if duration >= MINIMUM_DURATION:\n",
    "                attendance_data.loc[attendance_data['Name'] == name, period_col] += 1\n",
    "                attendance_data.loc[attendance_data['Name'] == name, 'Total'] += 1\n",
    "                total_days = (datetime.now().date() - attendance_data['Date'].min().date()).days + 1\n",
    "                attendance_data.loc[attendance_data['Name'] == name, 'Percentage'] = \\\n",
    "                    (attendance_data.loc[attendance_data['Name'] == name, 'Total'] / (total_days * TOTAL_PERIODS)) * 100\n",
    "                attendance_data.to_excel(attendance_file, index=False)\n",
    "\n",
    "# Update MongoDB with today's attendance and reset Excel\n",
    "def update_mongo_and_reset_excel(attendance_data):\n",
    "    for _, row in attendance_data.iterrows():\n",
    "        student_name = row['Name']\n",
    "        today_attendance = row['Percentage']\n",
    "        existing_record = collection.find_one({\"name\": student_name})\n",
    "        if existing_record:\n",
    "            prev_attendance = existing_record['attendance']\n",
    "            total_days_till_yesterday = existing_record['days']\n",
    "            cumulative_attendance = ((prev_attendance * total_days_till_yesterday) + today_attendance) / (total_days_till_yesterday + 1)\n",
    "            collection.update_one(\n",
    "                {\"name\": student_name},\n",
    "                {\"$set\": {\"attendance\": cumulative_attendance, \"days\": total_days_till_yesterday + 1}}\n",
    "            )\n",
    "        else:\n",
    "            collection.insert_one({\"name\": student_name, \"attendance\": today_attendance, \"days\": 1})\n",
    "    # Reset Excel file for a new day\n",
    "    attendance_data[['Total', 'Percentage']] = 0\n",
    "    for i in range(TOTAL_PERIODS):\n",
    "        attendance_data[f'Period {i+1}'] = 0\n",
    "    attendance_data['Date'] = datetime.now().date()\n",
    "    attendance_data.to_excel(r'D:\\minor\\Attend.xlsx', index=False)\n",
    "\n",
    "# Main loop to handle attendance processing\n",
    "def recognize_faces_multi_camera(known_faces, known_names):\n",
    "    cap_entry = cv2.VideoCapture(0)\n",
    "    cap_exit = cv2.VideoCapture(1)\n",
    "    attendance_data = initialize_attendance_file(known_names)\n",
    "    last_entry_times = {}\n",
    "\n",
    "    while True:\n",
    "        ret_entry, frame_entry = cap_entry.read()\n",
    "        ret_exit, frame_exit = cap_exit.read()\n",
    "        if not ret_entry or not ret_exit:\n",
    "            break\n",
    "        process_frame(frame_entry, 'entry', known_faces, known_names, attendance_data, last_entry_times)\n",
    "        process_frame(frame_exit, 'exit', known_faces, known_names, attendance_data, last_entry_times)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap_entry.release()\n",
    "    cap_exit.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    update_mongo_and_reset_excel(attendance_data)\n",
    "\n",
    "def process_frame(frame, event_type, known_faces, known_names, attendance_data, last_entry_times):\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    faces = RetinaFace.detect_faces(frame)\n",
    "    face_names = []\n",
    "    for face_key in faces.keys():\n",
    "        facial_area = faces[face_key][\"facial_area\"]\n",
    "        top, right, bottom, left = facial_area[1], facial_area[2], facial_area[3], facial_area[0]\n",
    "        encodings = face_recognition.face_encodings(frame_rgb, [(top, right, bottom, left)])\n",
    "        for encoding in encodings:\n",
    "            matches = face_recognition.compare_faces(known_faces, encoding, TOLERANCE)\n",
    "            face_distances = face_recognition.face_distance(known_faces, encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_names[best_match_index]\n",
    "                face_names.append(name)\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    for name in face_names:\n",
    "        if name != \"Unknown\":\n",
    "            update_attendance(name, timestamp, event_type, attendance_data, last_entry_times)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    known_faces, known_names = load_known_faces()\n",
    "    recognize_faces_multi_camera(known_faces, known_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Loaded known faces.\n",
      "Entry detected for v at 2024-11-03 13:06:00\n",
      "Updated attendance for v for Period 4 (duration: 1.67 mins)\n",
      "Exit detected for v at 2024-11-03 13:07:40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 192\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    191\u001b[0m     known_faces, known_names \u001b[38;5;241m=\u001b[39m load_known_faces()\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mrecognize_faces_multi_camera\u001b[49m\u001b[43m(\u001b[49m\u001b[43mknown_faces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 151\u001b[0m, in \u001b[0;36mrecognize_faces_multi_camera\u001b[1;34m(known_faces, known_names)\u001b[0m\n\u001b[0;32m    148\u001b[0m process_frame(frame_entry, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentry\u001b[39m\u001b[38;5;124m'\u001b[39m, known_faces, known_names, attendance_data, last_entry_times)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# Process exit camera\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m \u001b[43mprocess_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_exit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_faces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattendance_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_entry_times\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Display frames for entry and exit cameras\u001b[39;00m\n\u001b[0;32m    154\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntry Camera\u001b[39m\u001b[38;5;124m'\u001b[39m, frame_entry)\n",
      "Cell \u001b[1;32mIn[2], line 167\u001b[0m, in \u001b[0;36mprocess_frame\u001b[1;34m(frame, event_type, known_faces, known_names, attendance_data, last_entry_times)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_frame\u001b[39m(frame, event_type, known_faces, known_names, attendance_data, last_entry_times):\n\u001b[0;32m    166\u001b[0m     frame_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m--> 167\u001b[0m     faces \u001b[38;5;241m=\u001b[39m \u001b[43mRetinaFace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_faces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m     face_names \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m face_key \u001b[38;5;129;01min\u001b[39;00m faces\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\retinaface\\RetinaFace.py:123\u001b[0m, in \u001b[0;36mdetect_faces\u001b[1;34m(img_path, threshold, model, allow_upscaling)\u001b[0m\n\u001b[0;32m    121\u001b[0m landmarks_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    122\u001b[0m im_tensor, im_info, im_scale \u001b[38;5;241m=\u001b[39m preprocess\u001b[38;5;241m.\u001b[39mpreprocess_image(img, allow_upscaling)\n\u001b[1;32m--> 123\u001b[0m net_out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m net_out \u001b[38;5;241m=\u001b[39m [elt\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m elt \u001b[38;5;129;01min\u001b[39;00m net_out]\n\u001b[0;32m    125\u001b[0m sym_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from retinaface import RetinaFace\n",
    "import face_recognition\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# MongoDB setup\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['attendance_db']\n",
    "collection = db['students_attendance']\n",
    "\n",
    "# Directory containing known faces\n",
    "KNOWN_FACES_DIR = r\"D:\\minor\\Training_images\"\n",
    "TOLERANCE = 0.6\n",
    "FRAME_THICKNESS = 3\n",
    "FONT_THICKNESS = 2\n",
    "MODEL = \"cnn\"\n",
    "\n",
    "# Constants for periods and attendance calculation\n",
    "PERIOD_TIMES = [\n",
    "    (9, 10),   # Period 1: 9-10 am\n",
    "    (10, 11),  # Period 2: 10-11 am\n",
    "    (11, 12),  # Period 3: 11-12 pm\n",
    "    (13, 14),  # Period 4: 1-2 pm\n",
    "    (14, 15),  # Period 5: 2-3 pm\n",
    "    (15, 16)   # Period 6: 3-4 pm\n",
    "]\n",
    "TOTAL_PERIODS = len(PERIOD_TIMES)\n",
    "MINIMUM_DURATION = 1  # Minimum duration in minutes to log attendance\n",
    "\n",
    "# Load known faces and their encodings\n",
    "def load_known_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    for name in os.listdir(KNOWN_FACES_DIR):\n",
    "        for filename in os.listdir(f\"{KNOWN_FACES_DIR}/{name}\"):\n",
    "            image = face_recognition.load_image_file(f\"{KNOWN_FACES_DIR}/{name}/{filename}\")\n",
    "            encodings = face_recognition.face_encodings(image)\n",
    "            if encodings:\n",
    "                known_faces.append(encodings[0])\n",
    "                known_names.append(name)\n",
    "    print(\"Loaded known faces.\")\n",
    "    return known_faces, known_names\n",
    "\n",
    "# Initialize or update attendance file with columns for each period and Total and Percentage\n",
    "def initialize_attendance_file(known_names):\n",
    "    attendance_file = r'D:\\minor\\Attend.xlsx'\n",
    "    if not os.path.exists(attendance_file):\n",
    "        columns = ['Name', 'Date'] + [f'Period {i+1}' for i in range(TOTAL_PERIODS)] + ['Total', 'Percentage']\n",
    "        attendance_data = pd.DataFrame(columns=columns)\n",
    "        attendance_data['Name'] = pd.Series(known_names).unique()\n",
    "        attendance_data['Date'] = datetime.now().date()  # Set today's date\n",
    "        attendance_data.fillna(0, inplace=True)  # Set initial attendance to 0\n",
    "        attendance_data.to_excel(attendance_file, index=False)\n",
    "    else:\n",
    "        attendance_data = pd.read_excel(attendance_file, engine='openpyxl')\n",
    "    return attendance_data\n",
    "\n",
    "# Reset Excel attendance for a fresh day and update MongoDB\n",
    "def update_mongo_and_reset_excel(attendance_data):\n",
    "    attendance_file = r'D:\\minor\\Attend.xlsx'\n",
    "\n",
    "    for index, row in attendance_data.iterrows():\n",
    "        student_name = row['Name']\n",
    "        today_attendance = row['Percentage']\n",
    "\n",
    "        # Retrieve previous attendance data from MongoDB\n",
    "        existing_record = collection.find_one({\"name\": student_name})\n",
    "        if existing_record:\n",
    "            prev_attendance = existing_record['attendance']\n",
    "            total_days_till_yesterday = existing_record['days']\n",
    "            cumulative_attendance = ((prev_attendance * total_days_till_yesterday) + today_attendance) / (total_days_till_yesterday + 1)\n",
    "            \n",
    "            # Update the record in MongoDB\n",
    "            collection.update_one(\n",
    "                {\"name\": student_name},\n",
    "                {\"$set\": {\"attendance\": cumulative_attendance, \"days\": total_days_till_yesterday + 1}}\n",
    "            )\n",
    "            print(f\"Updated MongoDB for {student_name}: Attendance = {cumulative_attendance}, Days = {total_days_till_yesterday + 1}\")\n",
    "        else:\n",
    "            # Insert new record if it does not exist\n",
    "            collection.insert_one({\"name\": student_name, \"attendance\": today_attendance, \"days\": 1})\n",
    "            print(f\"Inserted new MongoDB record for {student_name}: Attendance = {today_attendance}, Days = 1\")\n",
    "\n",
    "    # Reset the Excel data for a new day\n",
    "    attendance_data['Total'] = 0\n",
    "    attendance_data['Percentage'] = 100\n",
    "    for i in range(TOTAL_PERIODS):\n",
    "        attendance_data[f'Period {i+1}'] = 0\n",
    "    attendance_data['Date'] = datetime.now().date()\n",
    "    attendance_data.to_excel(attendance_file, index=False)\n",
    "    print(\"Attendance Excel file reset for a new day.\")\n",
    "\n",
    "# Determine current period based on the current time\n",
    "def get_period_index(current_time):\n",
    "    for i, (start, end) in enumerate(PERIOD_TIMES):\n",
    "        if start <= current_time.hour < end:\n",
    "            return i  # Return the period index (0 for Period 1, etc.)\n",
    "    return None  # Return None if outside period times\n",
    "\n",
    "# Update attendance for each period based on entry and exit times\n",
    "def update_attendance(name, timestamp, event_type, attendance_data, last_entry_times):\n",
    "    attendance_file = r'D:\\minor\\Attend.xlsx'\n",
    "    current_time = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')\n",
    "    period_index = get_period_index(current_time)\n",
    "\n",
    "    if period_index is not None:\n",
    "        period_col = f'Period {period_index + 1}'\n",
    "\n",
    "        if event_type == 'entry':\n",
    "            last_entry_times[name] = current_time  # Store entry time\n",
    "        elif event_type == 'exit' and name in last_entry_times:\n",
    "            entry_time = last_entry_times.pop(name)  # Retrieve and remove the entry time\n",
    "            duration = (current_time - entry_time).total_seconds() / 60  # Convert to minutes\n",
    "\n",
    "            # Log attendance only if the duration is at least MINIMUM_DURATION\n",
    "            if duration >= MINIMUM_DURATION:\n",
    "                attendance_data.loc[attendance_data['Name'] == name, period_col] += 1\n",
    "                current_total = attendance_data.loc[attendance_data['Name'] == name, 'Total'].iloc[0]\n",
    "                new_total = current_total + 1  # Increase total attendance count by 1\n",
    "                attendance_data.loc[attendance_data['Name'] == name, 'Total'] = new_total\n",
    "                \n",
    "                # Calculate the attendance percentage\n",
    "                attendance_data.loc[attendance_data['Name'] == name, 'Percentage'] = (new_total / (TOTAL_PERIODS)) * 100\n",
    "                attendance_data.to_excel(attendance_file, index=False)\n",
    "                print(f\"Updated attendance for {name} for {period_col} (duration: {duration:.2f} mins)\")\n",
    "\n",
    "# Recognize faces from entry and exit cameras and process attendance\n",
    "def recognize_faces_multi_camera(known_faces, known_names):\n",
    "    cap_entry = cv2.VideoCapture(0)  # Entry camera\n",
    "    cap_exit = cv2.VideoCapture(1)   # Exit camera\n",
    "\n",
    "    attendance_data = initialize_attendance_file(known_names)\n",
    "    last_entry_times = {}  # Dictionary to track last entry times for each person\n",
    "\n",
    "    while True:\n",
    "        # Read frames from both entry and exit cameras\n",
    "        ret_entry, frame_entry = cap_entry.read()\n",
    "        ret_exit, frame_exit = cap_exit.read()\n",
    "        if not ret_entry or not ret_exit:\n",
    "            break\n",
    "\n",
    "        # Process entry camera\n",
    "        process_frame(frame_entry, 'entry', known_faces, known_names, attendance_data, last_entry_times)\n",
    "\n",
    "        # Process exit camera\n",
    "        process_frame(frame_exit, 'exit', known_faces, known_names, attendance_data, last_entry_times)\n",
    "\n",
    "        # Display frames for entry and exit cameras\n",
    "        cv2.imshow('Entry Camera', frame_entry)\n",
    "        cv2.imshow('Exit Camera', frame_exit)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap_entry.release()\n",
    "    cap_exit.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Process frames for entry or exit events\n",
    "def process_frame(frame, event_type, known_faces, known_names, attendance_data, last_entry_times):\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    faces = RetinaFace.detect_faces(frame)\n",
    "    face_names = []\n",
    "    for face_key in faces.keys():\n",
    "        facial_area = faces[face_key][\"facial_area\"]\n",
    "        top, right, bottom, left = facial_area[1], facial_area[2], facial_area[3], facial_area[0]\n",
    "        encodings = face_recognition.face_encodings(frame_rgb, [(top, right, bottom, left)])\n",
    "\n",
    "        for encoding in encodings:\n",
    "            matches = face_recognition.compare_faces(known_faces, encoding, TOLERANCE)\n",
    "            name = \"Unknown\"\n",
    "            face_distances = face_recognition.face_distance(known_faces, encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_names[best_match_index]\n",
    "            face_names.append(name)\n",
    "    # Log detected names and timestamps\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    for name in face_names:\n",
    "        if name != \"Unknown\":\n",
    "            update_attendance(name, timestamp, event_type, attendance_data, last_entry_times)\n",
    "            print(f\"{event_type.capitalize()} detected for {name} at {timestamp}\")\n",
    "\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    known_faces, known_names = load_known_faces()\n",
    "    recognize_faces_multi_camera(known_faces, known_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from retinaface import RetinaFace\n",
    "import face_recognition\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# MongoDB setup\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['attendance_db']\n",
    "collection = db['students_attendance']\n",
    "\n",
    "# Directory containing known faces\n",
    "KNOWN_FACES_DIR = r\"D:\\minor\\Training_images\"\n",
    "TOLERANCE = 0.6\n",
    "FRAME_THICKNESS = 3\n",
    "FONT_THICKNESS = 2\n",
    "MODEL = \"cnn\"\n",
    "\n",
    "# Constants for periods and attendance calculation\n",
    "PERIOD_TIMES = [\n",
    "    (9, 10),   # Period 1: 9-10 am\n",
    "    (10, 11),  # Period 2: 10-11 am\n",
    "    (11, 12),  # Period 3: 11-12 pm\n",
    "    (13, 14),  # Period 4: 1-2 pm\n",
    "    (14, 15),  # Period 5: 2-3 pm\n",
    "    (15, 16)   # Period 6: 3-4 pm\n",
    "]\n",
    "TOTAL_PERIODS = len(PERIOD_TIMES)\n",
    "MINIMUM_DURATION = 1  # Minimum duration in minutes to log attendance\n",
    "\n",
    "# Load known faces and their encodings\n",
    "def load_known_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    for name in os.listdir(KNOWN_FACES_DIR):\n",
    "        for filename in os.listdir(f\"{KNOWN_FACES_DIR}/{name}\"):\n",
    "            image = face_recognition.load_image_file(f\"{KNOWN_FACES_DIR}/{name}/{filename}\")\n",
    "            encodings = face_recognition.face_encodings(image)\n",
    "            if encodings:\n",
    "                known_faces.append(encodings[0])\n",
    "                known_names.append(name)\n",
    "    print(\"Loaded known faces.\")\n",
    "    return known_faces, known_names\n",
    "\n",
    "# Initialize or update attendance file with columns for each period and Total and Percentage\n",
    "def initialize_attendance_file(known_names):\n",
    "    attendance_file = r'D:\\minor\\Attend.xlsx'\n",
    "    if not os.path.exists(attendance_file):\n",
    "        columns = ['Name', 'Date'] + [f'Period {i+1}' for i in range(TOTAL_PERIODS)] + ['Total', 'Percentage']\n",
    "        attendance_data = pd.DataFrame(columns=columns)\n",
    "        attendance_data['Name'] = pd.Series(known_names).unique()\n",
    "        attendance_data['Date'] = datetime.now().date()  # Set today's date\n",
    "        attendance_data.fillna(0, inplace=True)  # Set initial attendance to 0\n",
    "        attendance_data.to_excel(attendance_file, index=False)\n",
    "    else:\n",
    "        attendance_data = pd.read_excel(attendance_file, engine='openpyxl')\n",
    "    return attendance_data\n",
    "\n",
    "# Reset Excel attendance for a fresh day and update MongoDB\n",
    "def update_mongo_and_reset_excel(attendance_data):\n",
    "    attendance_file = r'D:\\minor\\Attend.xlsx'\n",
    "\n",
    "    for index, row in attendance_data.iterrows():\n",
    "        student_name = row['Name']\n",
    "        today_attendance = row['Percentage']\n",
    "\n",
    "        # Retrieve previous attendance data from MongoDB\n",
    "        existing_record = collection.find_one({\"name\": student_name})\n",
    "        if existing_record:\n",
    "            prev_attendance = existing_record['attendance']\n",
    "            total_days_till_yesterday = existing_record['days']\n",
    "            cumulative_attendance = ((prev_attendance * total_days_till_yesterday) + today_attendance) / (total_days_till_yesterday + 1)\n",
    "            \n",
    "            # Update the record in MongoDB\n",
    "            collection.update_one(\n",
    "                {\"name\": student_name},\n",
    "                {\"$set\": {\"attendance\": cumulative_attendance, \"days\": total_days_till_yesterday + 1}}\n",
    "            )\n",
    "            print(f\"Updated MongoDB for {student_name}: Attendance = {cumulative_attendance}, Days = {total_days_till_yesterday + 1}\")\n",
    "        else:\n",
    "            # Insert new record if it does not exist\n",
    "            collection.insert_one({\"name\": student_name, \"attendance\": today_attendance, \"days\": 1})\n",
    "            print(f\"Inserted new MongoDB record for {student_name}: Attendance = {today_attendance}, Days = 1\")\n",
    "\n",
    "    # Reset the Excel data for a new day\n",
    "    attendance_data['Total'] = 0\n",
    "    attendance_data['Percentage'] = 100\n",
    "    for i in range(TOTAL_PERIODS):\n",
    "        attendance_data[f'Period {i+1}'] = 0\n",
    "    attendance_data['Date'] = datetime.now().date()\n",
    "    attendance_data.to_excel(attendance_file, index=False)\n",
    "    print(\"Attendance Excel file reset for a new day.\")\n",
    "\n",
    "# Determine current period based on the current time\n",
    "def get_period_index(current_time):\n",
    "    for i, (start, end) in enumerate(PERIOD_TIMES):\n",
    "        if start <= current_time.hour < end:\n",
    "            return i  # Return the period index (0 for Period 1, etc.)\n",
    "    return None  # Return None if outside period times\n",
    "\n",
    "# Update attendance for each period based on entry and exit times\n",
    "def update_attendance(name, timestamp, event_type, attendance_data, last_entry_times):\n",
    "    attendance_file = r'D:\\minor\\Attend.xlsx'\n",
    "    current_time = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')\n",
    "    period_index = get_period_index(current_time)\n",
    "\n",
    "    if period_index is not None:\n",
    "        period_col = f'Period {period_index + 1}'\n",
    "\n",
    "        if event_type == 'entry':\n",
    "            last_entry_times[name] = current_time  # Store entry time\n",
    "        elif event_type == 'exit' and name in last_entry_times:\n",
    "            entry_time = last_entry_times.pop(name)  # Retrieve and remove the entry time\n",
    "            duration = (current_time - entry_time).total_seconds() / 60  # Convert to minutes\n",
    "\n",
    "            # Log attendance only if the duration is at least MINIMUM_DURATION\n",
    "            if duration >= MINIMUM_DURATION:\n",
    "                attendance_data.loc[attendance_data['Name'] == name, period_col] += 1\n",
    "                current_total = attendance_data.loc[attendance_data['Name'] == name, 'Total'].iloc[0]\n",
    "                new_total = current_total + 1  # Increase total attendance count by 1\n",
    "                attendance_data.loc[attendance_data['Name'] == name, 'Total'] = new_total\n",
    "                \n",
    "                # Calculate the attendance percentage\n",
    "                attendance_data.loc[attendance_data['Name'] == name, 'Percentage'] = (new_total / (TOTAL_PERIODS)) * 100\n",
    "                attendance_data.to_excel(attendance_file, index=False)\n",
    "                print(f\"Updated attendance for {name} for {period_col} (duration: {duration:.2f} mins)\")\n",
    "\n",
    "# Recognize faces from entry and exit cameras and process attendance\n",
    "def recognize_faces_multi_camera(known_faces, known_names):\n",
    "    cap_entry = cv2.VideoCapture(0)  # Entry camera\n",
    "    cap_exit = cv2.VideoCapture(1)   # Exit camera\n",
    "\n",
    "    attendance_data = initialize_attendance_file(known_names)\n",
    "    last_entry_times = {}  # Dictionary to track last entry times for each person\n",
    "    last_update_day = datetime.now().day\n",
    "\n",
    "    while True:\n",
    "        # Read frames from both entry and exit cameras\n",
    "        ret_entry, frame_entry = cap_entry.read()\n",
    "        ret_exit, frame_exit = cap_exit.read()\n",
    "        if not ret_entry or not ret_exit:\n",
    "            break\n",
    "\n",
    "        # Process entry camera\n",
    "        process_frame(frame_entry, 'entry', known_faces, known_names, attendance_data, last_entry_times)\n",
    "\n",
    "        # Process exit camera\n",
    "        process_frame(frame_exit, 'exit', known_faces, known_names, attendance_data, last_entry_times)\n",
    "\n",
    "        # Check if the day has changed to update MongoDB and reset Excel file\n",
    "        if datetime.now().day != last_update_day:\n",
    "            update_mongo_and_reset_excel(attendance_data)\n",
    "            last_update_day = datetime.now().day\n",
    "\n",
    "        # Display frames for entry and exit cameras\n",
    "        cv2.imshow('Entry Camera', frame_entry)\n",
    "        cv2.imshow('Exit Camera', frame_exit)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Final update to MongoDB and reset Excel when the program ends\n",
    "    update_mongo_and_reset_excel(attendance_data)\n",
    "    cap_entry.release()\n",
    "    cap_exit.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Process frames for entry or exit events\n",
    "def process_frame(frame, event_type, known_faces, known_names, attendance_data, last_entry_times):\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    faces = RetinaFace.detect_faces(frame)\n",
    "    face_names = []\n",
    "    for face_key in faces.keys():\n",
    "        facial_area = faces[face_key][\"facial_area\"]\n",
    "        top, right, bottom, left = facial_area[1], facial_area[2], facial_area[3], facial_area[0]\n",
    "        face_encoding = face_recognition.face_encodings(frame_rgb, [(top, right, bottom, left)])\n",
    "        if not face_encoding:\n",
    "            continue\n",
    "        matches = face_recognition.compare_faces(known_faces, face_encoding[0], TOLERANCE)\n",
    "        face_distances = face_recognition.face_distance(known_faces, face_encoding[0])\n",
    "        best_match_index = np.argmin(face_distances) if matches else None\n",
    "        if best_match_index is not None and matches[best_match_index]:\n",
    "            name = known_names[best_match_index]\n",
    "            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            update_attendance(name, timestamp, event_type, attendance_data, last_entry_times)\n",
    "            print(f\"{name} - {event_type} detected at {timestamp}\")\n",
    "            face_names.append(name)\n",
    "    return face_names\n",
    "\n",
    "# Main script\n",
    "known_faces, known_names = load_known_faces()\n",
    "recognize_faces_multi_camera(known_faces, known_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_mongo_and_reset_excel(attendance_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update at prog end\n",
    "import cv2\n",
    "import numpy as np\n",
    "from retinaface import RetinaFace\n",
    "import face_recognition\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# MongoDB setup\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['attendance_db']\n",
    "collection = db['students_attendance']\n",
    "\n",
    "# Directory containing known faces\n",
    "KNOWN_FACES_DIR = r\"D:\\minor\\Training_images\"\n",
    "TOLERANCE = 0.6\n",
    "FRAME_THICKNESS = 3\n",
    "FONT_THICKNESS = 2\n",
    "MODEL = \"cnn\"\n",
    "\n",
    "# Constants for periods and attendance calculation\n",
    "PERIOD_TIMES = [\n",
    "    (9, 10),   # Period 1: 9-10 am\n",
    "    (10, 11),  # Period 2: 10-11 am\n",
    "    (11, 12),  # Period 3: 11-12 pm\n",
    "    (13, 14),  # Period 4: 1-2 pm\n",
    "    (14, 15),  # Period 5: 2-3 pm\n",
    "    (15, 16)   # Period 6: 3-4 pm\n",
    "]\n",
    "TOTAL_PERIODS = len(PERIOD_TIMES)\n",
    "MINIMUM_DURATION = 1  # Minimum duration in minutes to log attendance\n",
    "\n",
    "# Load known faces and their encodings\n",
    "def load_known_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    for name in os.listdir(KNOWN_FACES_DIR):\n",
    "        for filename in os.listdir(f\"{KNOWN_FACES_DIR}/{name}\"):\n",
    "            image = face_recognition.load_image_file(f\"{KNOWN_FACES_DIR}/{name}/{filename}\")\n",
    "            encodings = face_recognition.face_encodings(image)\n",
    "            if encodings:\n",
    "                known_faces.append(encodings[0])\n",
    "                known_names.append(name)\n",
    "    print(\"Loaded known faces.\")\n",
    "    return known_faces, known_names\n",
    "\n",
    "# Initialize or update attendance file with columns for each period and Total and Percentage\n",
    "def initialize_attendance_file(known_names):\n",
    "    attendance_file = r'D:\\minor\\Attend.xlsx'\n",
    "    if not os.path.exists(attendance_file):\n",
    "        columns = ['Name', 'Date'] + [f'Period {i+1}' for i in range(TOTAL_PERIODS)] + ['Total', 'Percentage']\n",
    "        attendance_data = pd.DataFrame(columns=columns)\n",
    "        attendance_data['Name'] = pd.Series(known_names).unique()\n",
    "        attendance_data['Date'] = datetime.now().date()  # Set today's date\n",
    "        attendance_data.fillna(0, inplace=True)  # Set initial attendance to 0\n",
    "        attendance_data.to_excel(attendance_file, index=False)\n",
    "    else:\n",
    "        attendance_data = pd.read_excel(attendance_file, engine='openpyxl')\n",
    "    return attendance_data\n",
    "\n",
    "# Reset Excel attendance for a fresh day and update MongoDB\n",
    "def update_mongo_and_reset_excel(attendance_data):\n",
    "    attendance_file = r'D:\\minor\\Attend.xlsx'\n",
    "\n",
    "    for index, row in attendance_data.iterrows():\n",
    "        student_name = row['Name']\n",
    "        today_attendance = row['Percentage']\n",
    "\n",
    "        # Retrieve previous attendance data from MongoDB\n",
    "        existing_record = collection.find_one({\"name\": student_name})\n",
    "        if existing_record:\n",
    "            prev_attendance = existing_record['attendance']\n",
    "            total_days_till_yesterday = existing_record['days']\n",
    "            cumulative_attendance = ((prev_attendance * total_days_till_yesterday) + today_attendance) / (total_days_till_yesterday + 1)\n",
    "            \n",
    "            # Update the record in MongoDB\n",
    "            collection.update_one(\n",
    "                {\"name\": student_name},\n",
    "                {\"$set\": {\"attendance\": cumulative_attendance, \"days\": total_days_till_yesterday + 1}}\n",
    "            )\n",
    "            print(f\"Updated MongoDB for {student_name}: Attendance = {cumulative_attendance}, Days = {total_days_till_yesterday + 1}\")\n",
    "        else:\n",
    "            # Insert new record if it does not exist\n",
    "            collection.insert_one({\"name\": student_name, \"attendance\": today_attendance, \"days\": 1})\n",
    "            print(f\"Inserted new MongoDB record for {student_name}: Attendance = {today_attendance}, Days = 1\")\n",
    "\n",
    "    # Reset the Excel data for a new day\n",
    "    attendance_data['Total'] = 0\n",
    "    attendance_data['Percentage'] = 100\n",
    "    for i in range(TOTAL_PERIODS):\n",
    "        attendance_data[f'Period {i+1}'] = 0\n",
    "    attendance_data['Date'] = datetime.now().date()\n",
    "    attendance_data.to_excel(attendance_file, index=False)\n",
    "    print(\"Attendance Excel file reset for a new day.\")\n",
    "\n",
    "# Determine current period based on the current time\n",
    "def get_period_index(current_time):\n",
    "    for i, (start, end) in enumerate(PERIOD_TIMES):\n",
    "        if start <= current_time.hour < end:\n",
    "            return i  # Return the period index (0 for Period 1, etc.)\n",
    "    return None  # Return None if outside period times\n",
    "\n",
    "# Update attendance for each period based on entry and exit times\n",
    "def update_attendance(name, timestamp, event_type, attendance_data, last_entry_times):\n",
    "    attendance_file = r'D:\\minor\\Attend.xlsx'\n",
    "    current_time = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')\n",
    "    period_index = get_period_index(current_time)\n",
    "\n",
    "    if period_index is not None:\n",
    "        period_col = f'Period {period_index + 1}'\n",
    "\n",
    "        if event_type == 'entry':\n",
    "            last_entry_times[name] = current_time  # Store entry time\n",
    "        elif event_type == 'exit' and name in last_entry_times:\n",
    "            entry_time = last_entry_times.pop(name)  # Retrieve and remove the entry time\n",
    "            duration = (current_time - entry_time).total_seconds() / 60  # Convert to minutes\n",
    "\n",
    "            # Log attendance only if the duration is at least MINIMUM_DURATION\n",
    "            if duration >= MINIMUM_DURATION:\n",
    "                attendance_data.loc[attendance_data['Name'] == name, period_col] += 1\n",
    "                current_total = attendance_data.loc[attendance_data['Name'] == name, 'Total'].iloc[0]\n",
    "                new_total = current_total + 1  # Increase total attendance count by 1\n",
    "                attendance_data.loc[attendance_data['Name'] == name, 'Total'] = new_total\n",
    "                \n",
    "                # Calculate the attendance percentage\n",
    "                attendance_data.loc[attendance_data['Name'] == name, 'Percentage'] = (new_total / (TOTAL_PERIODS)) * 100\n",
    "                attendance_data.to_excel(attendance_file, index=False)\n",
    "                print(f\"Updated attendance for {name} for {period_col} (duration: {duration:.2f} mins)\")\n",
    "\n",
    "# Recognize faces from entry and exit cameras and process attendance\n",
    "def recognize_faces_multi_camera(known_faces, known_names):\n",
    "    cap_entry = cv2.VideoCapture(0)  # Entry camera\n",
    "    cap_exit = cv2.VideoCapture(1)   # Exit camera\n",
    "\n",
    "    attendance_data = initialize_attendance_file(known_names)\n",
    "    last_entry_times = {}  # Dictionary to track last entry times for each person\n",
    "    last_update_day = datetime.now().day\n",
    "\n",
    "    while True:\n",
    "        # Read frames from both entry and exit cameras\n",
    "        ret_entry, frame_entry = cap_entry.read()\n",
    "        ret_exit, frame_exit = cap_exit.read()\n",
    "        if not ret_entry or not ret_exit:\n",
    "            break\n",
    "\n",
    "        # Process entry camera\n",
    "        process_frame(frame_entry, 'entry', known_faces, known_names, attendance_data, last_entry_times)\n",
    "\n",
    "        # Process exit camera\n",
    "        process_frame(frame_exit, 'exit', known_faces, known_names, attendance_data, last_entry_times)\n",
    "\n",
    "        # Check if the day has changed to update MongoDB and reset Excel file\n",
    "        if datetime.now().day != last_update_day:\n",
    "            update_mongo_and_reset_excel(attendance_data)\n",
    "            last_update_day = datetime.now().day\n",
    "\n",
    "        # Display frames for entry and exit cameras\n",
    "        cv2.imshow('Entry Camera', frame_entry)\n",
    "        cv2.imshow('Exit Camera', frame_exit)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Final update to MongoDB and reset Excel when the program ends\n",
    "    update_mongo_and_reset_excel(attendance_data)\n",
    "    cap_entry.release()\n",
    "    cap_exit.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Process frames for entry or exit events\n",
    "def process_frame(frame, event_type, known_faces, known_names, attendance_data, last_entry_times):\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    faces = RetinaFace.detect_faces(frame)\n",
    "    face_names = []\n",
    "    for face_key in faces.keys():\n",
    "        facial_area = faces[face_key][\"facial_area\"]\n",
    "        top, right, bottom, left = facial_area[1], facial_area[2], facial_area[3], facial_area[0]\n",
    "        face_encoding = face_recognition.face_encodings(frame_rgb, [(top, right, bottom, left)])\n",
    "        if not face_encoding:\n",
    "            continue\n",
    "        matches = face_recognition.compare_faces(known_faces, face_encoding[0], TOLERANCE)\n",
    "        face_distances = face_recognition.face_distance(known_faces, face_encoding[0])\n",
    "        best_match_index = np.argmin(face_distances) if matches else None\n",
    "        if best_match_index is not None and matches[best_match_index]:\n",
    "            name = known_names[best_match_index]\n",
    "            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            update_attendance(name, timestamp, event_type, attendance_data, last_entry_times)\n",
    "            print(f\"{name} - {event_type} detected at {timestamp}\")\n",
    "            face_names.append(name)\n",
    "    return face_names\n",
    "\n",
    "# Main script\n",
    "known_faces, known_names = load_known_faces()\n",
    "recognize_faces_multi_camera(known_faces, known_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update at 5pm\n",
    "import cv2\n",
    "import numpy as np\n",
    "from retinaface import RetinaFace\n",
    "import face_recognition\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# MongoDB setup\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['attendance_db']\n",
    "collection = db['students_attendance']\n",
    "\n",
    "# Directory containing known faces\n",
    "KNOWN_FACES_DIR = r\"D:\\minor\\Training_images\"\n",
    "TOLERANCE = 0.6\n",
    "FRAME_THICKNESS = 3\n",
    "FONT_THICKNESS = 2\n",
    "MODEL = \"cnn\"\n",
    "\n",
    "# Constants for periods and attendance calculation\n",
    "PERIOD_TIMES = [\n",
    "    (9, 10),   # Period 1: 9-10 am\n",
    "    (10, 11),  # Period 2: 10-11 am\n",
    "    (11, 12),  # Period 3: 11-12 pm\n",
    "    (13, 14),  # Period 4: 1-2 pm\n",
    "    (14, 15),  # Period 5: 2-3 pm\n",
    "    (15, 16)   # Period 6: 3-4 pm\n",
    "]\n",
    "TOTAL_PERIODS = len(PERIOD_TIMES)\n",
    "MINIMUM_DURATION = 1  # Minimum duration in minutes to log attendance\n",
    "\n",
    "# Load known faces and their encodings\n",
    "def load_known_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    for name in os.listdir(KNOWN_FACES_DIR):\n",
    "        for filename in os.listdir(f\"{KNOWN_FACES_DIR}/{name}\"):\n",
    "            image = face_recognition.load_image_file(f\"{KNOWN_FACES_DIR}/{name}/{filename}\")\n",
    "            encodings = face_recognition.face_encodings(image)\n",
    "            if encodings:\n",
    "                known_faces.append(encodings[0])\n",
    "                known_names.append(name)\n",
    "    print(\"Loaded known faces.\")\n",
    "    return known_faces, known_names\n",
    "\n",
    "# Initialize or update attendance file with columns for each period and Total and Percentage\n",
    "def initialize_attendance_file(known_names):\n",
    "    attendance_file = r'D:\\minor\\Attend.xlsx'\n",
    "    if not os.path.exists(attendance_file):\n",
    "        columns = ['Name', 'Date'] + [f'Period {i+1}' for i in range(TOTAL_PERIODS)] + ['Total', 'Percentage']\n",
    "        attendance_data = pd.DataFrame(columns=columns)\n",
    "        attendance_data['Name'] = pd.Series(known_names).unique()\n",
    "        attendance_data['Date'] = datetime.now().date()  # Set today's date\n",
    "        attendance_data.fillna(0, inplace=True)  # Set initial attendance to 0\n",
    "        attendance_data.to_excel(attendance_file, index=False)\n",
    "    else:\n",
    "        attendance_data = pd.read_excel(attendance_file, engine='openpyxl')\n",
    "    return attendance_data\n",
    "\n",
    "# Reset Excel attendance for a fresh day and update MongoDB\n",
    "def update_mongo_and_reset_excel(attendance_data):\n",
    "    attendance_file = r'D:\\minor\\Attend.xlsx'\n",
    "\n",
    "    for index, row in attendance_data.iterrows():\n",
    "        student_name = row['Name']\n",
    "        today_attendance = row['Percentage']\n",
    "\n",
    "        # Retrieve previous attendance data from MongoDB\n",
    "        existing_record = collection.find_one({\"name\": student_name})\n",
    "        if existing_record:\n",
    "            prev_attendance = existing_record['attendance']\n",
    "            total_days_till_yesterday = existing_record['days']\n",
    "            cumulative_attendance = ((prev_attendance * total_days_till_yesterday) + today_attendance) / (total_days_till_yesterday + 1)\n",
    "            \n",
    "            # Update the record in MongoDB\n",
    "            collection.update_one(\n",
    "                {\"name\": student_name},\n",
    "                {\"$set\": {\"attendance\": cumulative_attendance, \"days\": total_days_till_yesterday + 1}}\n",
    "            )\n",
    "            print(f\"Updated MongoDB for {student_name}: Attendance = {cumulative_attendance}, Days = {total_days_till_yesterday + 1}\")\n",
    "        else:\n",
    "            # Insert new record if it does not exist\n",
    "            collection.insert_one({\"name\": student_name, \"attendance\": today_attendance, \"days\": 1})\n",
    "            print(f\"Inserted new MongoDB record for {student_name}: Attendance = {today_attendance}, Days = 1\")\n",
    "\n",
    "    # Reset the Excel data for a new day\n",
    "    attendance_data['Total'] = 0\n",
    "    attendance_data['Percentage'] = 100\n",
    "    for i in range(TOTAL_PERIODS):\n",
    "        attendance_data[f'Period {i+1}'] = 0\n",
    "    attendance_data['Date'] = datetime.now().date()\n",
    "    attendance_data.to_excel(attendance_file, index=False)\n",
    "    print(\"Attendance Excel file reset for a new day.\")\n",
    "\n",
    "# Determine current period based on the current time\n",
    "def get_period_index(current_time):\n",
    "    for i, (start, end) in enumerate(PERIOD_TIMES):\n",
    "        if start <= current_time.hour < end:\n",
    "            return i  # Return the period index (0 for Period 1, etc.)\n",
    "    return None  # Return None if outside period times\n",
    "\n",
    "# Update attendance for each period based on entry and exit times\n",
    "def update_attendance(name, timestamp, event_type, attendance_data, last_entry_times):\n",
    "    attendance_file = r'D:\\minor\\Attend.xlsx'\n",
    "    current_time = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')\n",
    "    period_index = get_period_index(current_time)\n",
    "\n",
    "    if period_index is not None:\n",
    "        period_col = f'Period {period_index + 1}'\n",
    "\n",
    "        if event_type == 'entry':\n",
    "            last_entry_times[name] = current_time  # Store entry time\n",
    "        elif event_type == 'exit' and name in last_entry_times:\n",
    "            entry_time = last_entry_times.pop(name)  # Retrieve and remove the entry time\n",
    "            duration = (current_time - entry_time).total_seconds() / 60  # Convert to minutes\n",
    "\n",
    "            # Log attendance only if the duration is at least MINIMUM_DURATION\n",
    "            if duration >= MINIMUM_DURATION:\n",
    "                attendance_data.loc[attendance_data['Name'] == name, period_col] += 1\n",
    "                current_total = attendance_data.loc[attendance_data['Name'] == name, 'Total'].iloc[0]\n",
    "                new_total = current_total + 1  # Increase total attendance count by 1\n",
    "                attendance_data.loc[attendance_data['Name'] == name, 'Total'] = new_total\n",
    "                \n",
    "                # Calculate the attendance percentage\n",
    "                attendance_data.loc[attendance_data['Name'] == name, 'Percentage'] = (new_total / (TOTAL_PERIODS)) * 100\n",
    "                attendance_data.to_excel(attendance_file, index=False)\n",
    "                print(f\"Updated attendance for {name} for {period_col} (duration: {duration:.2f} mins)\")\n",
    "\n",
    "# Recognize faces from entry and exit cameras and process attendance\n",
    "def recognize_faces_multi_camera(known_faces, known_names):\n",
    "    cap_entry = cv2.VideoCapture(0)  # Entry camera\n",
    "    cap_exit = cv2.VideoCapture(1)   # Exit camera\n",
    "\n",
    "    attendance_data = initialize_attendance_file(known_names)\n",
    "    last_entry_times = {}  # Dictionary to track last entry times for each person\n",
    "\n",
    "    while True:\n",
    "        # Get current time and check if it's 5 PM for the MongoDB update\n",
    "        current_time = datetime.now()\n",
    "        if current_time.hour == 17 and current_time.minute == 0:\n",
    "            update_mongo_and_reset_excel(attendance_data)\n",
    "            print(\"Attendance data updated to MongoDB at 5 PM and Excel sheet reset for the new day.\")\n",
    "\n",
    "        # Read frames from both entry and exit cameras\n",
    "        ret_entry, frame_entry = cap_entry.read()\n",
    "        ret_exit, frame_exit = cap_exit.read()\n",
    "        if not ret_entry or not ret_exit:\n",
    "            break\n",
    "\n",
    "        # Process entry camera\n",
    "        process_frame(frame_entry, 'entry', known_faces, known_names, attendance_data, last_entry_times)\n",
    "\n",
    "        # Process exit camera\n",
    "        process_frame(frame_exit, 'exit', known_faces, known_names, attendance_data, last_entry_times)\n",
    "\n",
    "        # Display frames for entry and exit cameras\n",
    "        cv2.imshow('Entry Camera', frame_entry)\n",
    "        cv2.imshow('Exit Camera', frame_exit)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap_entry.release()\n",
    "    cap_exit.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Process frames for entry or exit events\n",
    "def process_frame(frame, event_type, known_faces, known_names, attendance_data, last_entry_times):\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    faces = RetinaFace.detect_faces(frame)\n",
    "    face_names = []\n",
    "    for face_key in faces.keys():\n",
    "        facial_area = faces[face_key][\"facial_area\"]\n",
    "        top, right, bottom, left = facial_area[1], facial_area[2], facial_area[3], facial_area[0]\n",
    "        face_encoding = face_recognition.face_encodings(frame_rgb, [(top, right, bottom, left)])\n",
    "        if not face_encoding:\n",
    "            continue\n",
    "        matches = face_recognition.compare_faces(known_faces, face_encoding[0], TOLERANCE)\n",
    "        face_distances = face_recognition.face_distance(known_faces, face_encoding[0])\n",
    "        best_match_index = np.argmin(face_distances) if matches else None\n",
    "        if best_match_index is not None and matches[best_match_index]:\n",
    "            name = known_names[best_match_index]\n",
    "            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            update_attendance(name, timestamp, event_type, attendance_data, last_entry_times)\n",
    "            print(f\"{name} - {event_type} detected at {timestamp}\")\n",
    "            face_names.append(name)\n",
    "    return face_names\n",
    "\n",
    "# Main script\n",
    "known_faces, known_names = load_known_faces()\n",
    "recognize_faces_multi_camera(known_faces, known_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\B VISHNU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Loaded known faces.\n",
      "Vishnu - entry detected at 2024-11-04 10:29:12\n",
      "Vamshi - entry detected at 2024-11-04 10:29:42\n",
      "Shreyesh - entry detected at 2024-11-04 10:30:40\n",
      "Shreyesh - entry detected at 2024-11-04 10:31:41\n",
      "Vamshi - entry detected at 2024-11-04 10:31:42\n",
      "Updated attendance for Vamshi for Period 2 (duration: 2.63 mins)\n",
      "Vamshi - exit detected at 2024-11-04 10:34:20\n",
      "Updated attendance for Shreyesh for Period 2 (duration: 2.65 mins)\n",
      "Shreyesh - exit detected at 2024-11-04 10:34:20\n",
      "Updated attendance for Vishnu for Period 2 (duration: 8.65 mins)\n",
      "Vishnu - exit detected at 2024-11-04 10:37:51\n"
     ]
    }
   ],
   "source": [
    "#testing to update at 1 30 pm\n",
    "import cv2\n",
    "import numpy as np\n",
    "from retinaface import RetinaFace\n",
    "import face_recognition\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# MongoDB setup\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['attendance_db']\n",
    "collection = db['students_attendance']\n",
    "\n",
    "# Directory containing known faces\n",
    "KNOWN_FACES_DIR = r\"D:\\minor\\Training_images\"\n",
    "TOLERANCE = 0.6\n",
    "FRAME_THICKNESS = 3\n",
    "FONT_THICKNESS = 2\n",
    "MODEL = \"cnn\"\n",
    "\n",
    "# Constants for periods and attendance calculation\n",
    "PERIOD_TIMES = [\n",
    "    (9, 10),   # Period 1: 9-10 am\n",
    "    (10, 11),  # Period 2: 10-11 am\n",
    "    (11, 12),  # Period 3: 11-12 pm\n",
    "    (13, 14),  # Period 4: 1-2 pm\n",
    "    (14, 15),  # Period 5: 2-3 pm\n",
    "    (15, 16)   # Period 6: 3-4 pm\n",
    "]\n",
    "TOTAL_PERIODS = len(PERIOD_TIMES)\n",
    "MINIMUM_DURATION = 1  # Minimum duration in minutes to log attendance\n",
    "\n",
    "# Load known faces and their encodings\n",
    "def load_known_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    for name in os.listdir(KNOWN_FACES_DIR):\n",
    "        for filename in os.listdir(f\"{KNOWN_FACES_DIR}/{name}\"):\n",
    "            image = face_recognition.load_image_file(f\"{KNOWN_FACES_DIR}/{name}/{filename}\")\n",
    "            encodings = face_recognition.face_encodings(image)\n",
    "            if encodings:\n",
    "                known_faces.append(encodings[0])\n",
    "                known_names.append(name)\n",
    "    print(\"Loaded known faces.\")\n",
    "    return known_faces, known_names\n",
    "\n",
    "# Initialize or update attendance file with columns for each period and Total and Percentage\n",
    "def initialize_attendance_file(known_names):\n",
    "    attendance_file = r'D:\\minor\\Attend.xlsx'\n",
    "    if not os.path.exists(attendance_file):\n",
    "        columns = ['Name', 'Date'] + [f'Period {i+1}' for i in range(TOTAL_PERIODS)] + ['Total', 'Percentage']\n",
    "        attendance_data = pd.DataFrame(columns=columns)\n",
    "        attendance_data['Name'] = pd.Series(known_names).unique()\n",
    "        attendance_data['Date'] = datetime.now().date()  # Set today's date\n",
    "        attendance_data.fillna(0, inplace=True)  # Set initial attendance to 0\n",
    "        attendance_data.to_excel(attendance_file, index=False)\n",
    "    else:\n",
    "        attendance_data = pd.read_excel(attendance_file, engine='openpyxl')\n",
    "    return attendance_data\n",
    "\n",
    "# Reset Excel attendance for a fresh day and update MongoDB\n",
    "def update_mongo_and_reset_excel(attendance_data):\n",
    "    attendance_file = r'D:\\minor\\Attend.xlsx'\n",
    "\n",
    "    for index, row in attendance_data.iterrows():\n",
    "        student_name = row['Name']\n",
    "        today_attendance = row['Percentage']\n",
    "\n",
    "        # Retrieve previous attendance data from MongoDB\n",
    "        existing_record = collection.find_one({\"name\": student_name})\n",
    "        if existing_record:\n",
    "            prev_attendance = existing_record['attendance']\n",
    "            total_days_till_yesterday = existing_record['days']\n",
    "            cumulative_attendance = ((prev_attendance * total_days_till_yesterday) + today_attendance) / (total_days_till_yesterday + 1)\n",
    "            \n",
    "            # Update the record in MongoDB\n",
    "            collection.update_one(\n",
    "                {\"name\": student_name},\n",
    "                {\"$set\": {\"attendance\": cumulative_attendance, \"days\": total_days_till_yesterday + 1}}\n",
    "            )\n",
    "            print(f\"Updated MongoDB for {student_name}: Attendance = {cumulative_attendance}, Days = {total_days_till_yesterday + 1}\")\n",
    "        else:\n",
    "            # Insert new record if it does not exist\n",
    "            collection.insert_one({\"name\": student_name, \"attendance\": today_attendance, \"days\": 1})\n",
    "            print(f\"Inserted new MongoDB record for {student_name}: Attendance = {today_attendance}, Days = 1\")\n",
    "\n",
    "    # Reset the Excel data for a new day\n",
    "    attendance_data['Total'] = 0\n",
    "    attendance_data['Percentage'] = 100\n",
    "    for i in range(TOTAL_PERIODS):\n",
    "        attendance_data[f'Period {i+1}'] = 0\n",
    "    attendance_data['Date'] = datetime.now().date()\n",
    "    attendance_data.to_excel(attendance_file, index=False)\n",
    "    print(\"Attendance Excel file reset for a new day.\")\n",
    "\n",
    "# Determine current period based on the current time\n",
    "def get_period_index(current_time):\n",
    "    for i, (start, end) in enumerate(PERIOD_TIMES):\n",
    "        if start <= current_time.hour < end:\n",
    "            return i  # Return the period index (0 for Period 1, etc.)\n",
    "    return None  # Return None if outside period times\n",
    "\n",
    "# Update attendance for each period based on entry and exit times\n",
    "def update_attendance(name, timestamp, event_type, attendance_data, last_entry_times):\n",
    "    attendance_file = r'D:\\minor\\Attend.xlsx'\n",
    "    current_time = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')\n",
    "    period_index = get_period_index(current_time)\n",
    "\n",
    "    if period_index is not None:\n",
    "        period_col = f'Period {period_index + 1}'\n",
    "\n",
    "        if event_type == 'entry':\n",
    "            last_entry_times[name] = current_time  # Store entry time\n",
    "        elif event_type == 'exit' and name in last_entry_times:\n",
    "            entry_time = last_entry_times.pop(name)  # Retrieve and remove the entry time\n",
    "            duration = (current_time - entry_time).total_seconds() / 60  # Convert to minutes\n",
    "\n",
    "            # Log attendance only if the duration is at least MINIMUM_DURATION\n",
    "            if duration >= MINIMUM_DURATION:\n",
    "                attendance_data.loc[attendance_data['Name'] == name, period_col] += 1\n",
    "                current_total = attendance_data.loc[attendance_data['Name'] == name, 'Total'].iloc[0]\n",
    "                new_total = current_total + 1  # Increase total attendance count by 1\n",
    "                attendance_data.loc[attendance_data['Name'] == name, 'Total'] = new_total\n",
    "                \n",
    "                # Calculate the attendance percentage\n",
    "                attendance_data.loc[attendance_data['Name'] == name, 'Percentage'] = (new_total / (TOTAL_PERIODS)) * 100\n",
    "                attendance_data.to_excel(attendance_file, index=False)\n",
    "                print(f\"Updated attendance for {name} for {period_col} (duration: {duration:.2f} mins)\")\n",
    "\n",
    "# Recognize faces from entry and exit cameras and process attendance\n",
    "def recognize_faces_multi_camera(known_faces, known_names):\n",
    "    global last_update_date\n",
    "    cap_entry = cv2.VideoCapture(0)  # Entry camera\n",
    "    cap_exit = cv2.VideoCapture(1)   # Exit camera\n",
    "\n",
    "    attendance_data = initialize_attendance_file(known_names)\n",
    "    last_entry_times = {}  # Dictionary to track last entry times for each person\n",
    "\n",
    "    while True:\n",
    "       \n",
    "        current_time = datetime.now()\n",
    "        if current_time.hour == 13 and current_time.minute == 34 and (last_update_date!=current_time.date()):\n",
    "            update_mongo_and_reset_excel(attendance_data)\n",
    "            last_update_date=current_time.date()\n",
    "            print(\"Attendance data updated to MongoDB at 5 PM and Excel sheet reset for the new day.\")\n",
    "\n",
    "        # Read frames from both entry and exit cameras\n",
    "        ret_entry, frame_entry = cap_entry.read()\n",
    "        ret_exit, frame_exit = cap_exit.read()\n",
    "        if not ret_entry or not ret_exit:\n",
    "            break\n",
    "\n",
    "        # Process entry camera\n",
    "        process_frame(frame_entry, 'entry', known_faces, known_names, attendance_data, last_entry_times)\n",
    "\n",
    "        # Process exit camera\n",
    "        process_frame(frame_exit, 'exit', known_faces, known_names, attendance_data, last_entry_times)\n",
    "\n",
    "        # Display frames for entry and exit cameras\n",
    "        cv2.imshow('Entry Camera', frame_entry)\n",
    "        cv2.imshow('Exit Camera', frame_exit)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap_entry.release()\n",
    "    cap_exit.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Process frames for entry or exit events\n",
    "def process_frame(frame, event_type, known_faces, known_names, attendance_data, last_entry_times):\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    faces = RetinaFace.detect_faces(frame)\n",
    "    face_names = []\n",
    "    for face_key in faces.keys():\n",
    "        facial_area = faces[face_key][\"facial_area\"]\n",
    "        top, right, bottom, left = facial_area[1], facial_area[2], facial_area[3], facial_area[0]\n",
    "        face_encoding = face_recognition.face_encodings(frame_rgb, [(top, right, bottom, left)])\n",
    "        if not face_encoding:\n",
    "            continue\n",
    "        matches = face_recognition.compare_faces(known_faces, face_encoding[0], TOLERANCE)\n",
    "        face_distances = face_recognition.face_distance(known_faces, face_encoding[0])\n",
    "        best_match_index = np.argmin(face_distances) if matches else None\n",
    "        if best_match_index is not None and matches[best_match_index]:\n",
    "            name = known_names[best_match_index]\n",
    "            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            update_attendance(name, timestamp, event_type, attendance_data, last_entry_times)\n",
    "            print(f\"{name} - {event_type} detected at {timestamp}\")\n",
    "            face_names.append(name)\n",
    "    return face_names\n",
    "\n",
    "# Main script\n",
    "known_faces, known_names = load_known_faces()\n",
    "recognize_faces_multi_camera(known_faces, known_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
